{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the common point between all\n",
      "those robots\n",
      "well all the robots you see here are\n",
      "or can be powered by rouse\n",
      "roth means robot operating system\n",
      "it is something between a middleware\n",
      "and a framework built especially for\n",
      "robotics applications rao's goal\n",
      "is to provide a standard for robotic\n",
      "software\n",
      "that developers can use and reuse in\n",
      "any robot once you know how to use ros\n",
      "efficiently you will be able to set up\n",
      "a new software for a new robot in no\n",
      "time\n",
      "you first need to master the basics and\n",
      "core functionalities\n",
      "which you will see in this course and\n",
      "then\n",
      "for every new robot you program you will\n",
      "gain more skills\n",
      "that can apply to other robots\n",
      "the more you know about ross the easiest\n",
      "it will be for you to program and\n",
      "understand\n",
      "the code of any robot\n",
      "but is that it no another\n",
      "philosophy behind ross is don't reinvent\n",
      "the wheel reinventing the wheel is a\n",
      "very common problem\n",
      "in robotics people always start building\n",
      "new software\n",
      "that is already existing and thus they\n",
      "don't have the time\n",
      "to work on really valuable stuff\n",
      "what if instead you could build on a\n",
      "strong\n",
      "software base to directly program\n",
      "high-level functionalities\n",
      "and work on use cases instead of\n",
      "low-level technical stuff that already\n",
      "exists in way\n",
      "so this is the why behind ross\n",
      "now when to use ros maybe\n",
      "you've already started to program robots\n",
      "with\n",
      "an arduino board with a custom code\n",
      "on a computer and what you will quickly\n",
      "experience\n",
      "is that the more sensors actuators\n",
      "controllers you add on your application\n",
      "the more complex\n",
      "it becomes until you reach a point\n",
      "where everything is mixed up and\n",
      "you can't add any code for a new sensor\n",
      "without having a huge headache\n",
      "ross is here to help you develop\n",
      "powerful\n",
      "and scalable robotic applications\n",
      "you can use it whenever you want to\n",
      "create a robot software\n",
      "which needs a lot of communication\n",
      "between its\n",
      "sub-programs or has some functionalities\n",
      "that go beyond a very simple use case\n",
      "etc so for a robot\n",
      "that will just open a door with a servo\n",
      "motor when it detects a movement\n",
      "maybe you don't need routes but for a\n",
      "mobile robot\n",
      "which you want to control with a gps and\n",
      "a camera\n",
      "in this case ross might really help you\n",
      "alright you've just seen what is the why\n",
      "behind ross\n",
      "and when to use it now what is ross\n",
      "it would be hard to describe exactly\n",
      "what is ross in about two minutes\n",
      "even an hour but here are two main\n",
      "points\n",
      "that will give you an idea of the big\n",
      "picture\n",
      "first of all ross provides you with a\n",
      "way of\n",
      "separating your code into reusable\n",
      "blocks\n",
      "along with a set of communication tools\n",
      "to easily communicate between all your\n",
      "sub-programs\n",
      "let's say that you are programming a\n",
      "robotic arm\n",
      "you can create a subprogram called\n",
      "node for your camera another for the\n",
      "motion planning\n",
      "another one for the hardware driver\n",
      "another for\n",
      "joystick and so on\n",
      "and each of those independent blocks\n",
      "will communicate\n",
      "between each other in a way that\n",
      "is powerful and scalable\n",
      "the second main point is that ross\n",
      "provides you with many plug-and-play\n",
      "libraries\n",
      "that will save you a huge amount of time\n",
      "and most importantly that will prevent\n",
      "you\n",
      "from reinventing the wheel if we come\n",
      "back to the robotic arm\n",
      "imagine how difficult it can be to\n",
      "compute\n",
      "the inverse kinematic for the arm to\n",
      "plan a trajectory\n",
      "which will make the arm move smoothly\n",
      "and\n",
      "avoid any obstacle on the way\n",
      "impossible you might think unless you\n",
      "spend\n",
      "two years studying mathematics motion\n",
      "planning\n",
      "etc but what if i tell you this\n",
      "you don't need two years you need maybe\n",
      "two days\n",
      "to install a library and figure out\n",
      "how to use it so you have great\n",
      "communication tools\n",
      "and great libraries that's not all\n",
      "ros is said to be language agnostic\n",
      "it means that you can program some parts\n",
      "of your application\n",
      "in a programming language and another\n",
      "part\n",
      "in another programming language simply\n",
      "because\n",
      "the communication tools don't rely on a\n",
      "specific\n",
      "language so in this course we will not\n",
      "go into\n",
      "all the external libraries that exist\n",
      "for many different robots\n",
      "we will mostly focus on the ros basics\n",
      "and core functionalities that will\n",
      "enable you\n",
      "to easily start any robot application\n",
      "powered by ros\n",
      "using python and c plus plus\n",
      "ros is also open source with an\n",
      "active and growing community so\n",
      "you can directly see what's going on you\n",
      "can get help\n",
      "share your project and even contribute\n",
      "if you wish to all right with this quick\n",
      "introduction\n",
      "you should get some ideas about what is\n",
      "wrong\n",
      "when to use it and why it is useful\n",
      "don't panic though if you don't\n",
      "understand everything right now\n",
      "the big picture behind ross is pretty\n",
      "hard to get\n",
      "at the beginning but after some practice\n",
      "you will start to get it and i can\n",
      "guarantee you\n",
      "that you will quickly think that ross\n",
      "is awesome\n"
     ]
    }
   ],
   "source": [
    "def get_youtube_transcript(video_url: str) -> list:\n",
    "    video_id = video_url.split(\"v=\")[1]\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    return transcript\n",
    "video_url = \"https://www.youtube.com/watch?v=8QfI5a7lTKU\"\n",
    "video_id = video_url.split(\"v=\")[1]\n",
    "\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "for segment in transcript:\n",
    "    print(segment['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript stored into MongoDB\n"
     ]
    }
   ],
   "source": [
    "## MongoDB\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")  # Replace with your MongoDB connection string\n",
    "db = client[\"youtube_database\"]  # Database name\n",
    "collection = db[\"transcripts\"]   # Collection name\n",
    "\n",
    "# Insert into MongoDB\n",
    "document = {\n",
    "    \"source\": \"youtube\",\n",
    "    \"video_id\": video_id,\n",
    "    \"transcript\": transcript\n",
    "}\n",
    "\n",
    "collection.insert_one(document)\n",
    "print(\"Transcript stored into MongoDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_id', 'source', 'video_id', 'transcript'])\n"
     ]
    }
   ],
   "source": [
    "result = collection.find_one({\"video_id\": video_id})\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what is the common point between all', 'those robots', 'well all the robots you see here are', 'or can be powered by rouse', 'roth means robot operating system', 'it is something between a middleware', 'and a framework built especially for', \"robotics applications rao's goal\", 'is to provide a standard for robotic', 'software', 'that developers can use and reuse in', 'any robot once you know how to use ros', 'efficiently you will be able to set up', 'a new software for a new robot in no', 'time', 'you first need to master the basics and', 'core functionalities', 'which you will see in this course and', 'then', 'for every new robot you program you will', 'gain more skills', 'that can apply to other robots', 'the more you know about ross the easiest', 'it will be for you to program and', 'understand', 'the code of any robot', 'but is that it no another', \"philosophy behind ross is don't reinvent\", 'the wheel reinventing the wheel is a', 'very common problem', 'in robotics people always start building', 'new software', 'that is already existing and thus they', \"don't have the time\", 'to work on really valuable stuff', 'what if instead you could build on a', 'strong', 'software base to directly program', 'high-level functionalities', 'and work on use cases instead of', 'low-level technical stuff that already', 'exists in way', 'so this is the why behind ross', 'now when to use ros maybe', \"you've already started to program robots\", 'with', 'an arduino board with a custom code', 'on a computer and what you will quickly', 'experience', 'is that the more sensors actuators', 'controllers you add on your application', 'the more complex', 'it becomes until you reach a point', 'where everything is mixed up and', \"you can't add any code for a new sensor\", 'without having a huge headache', 'ross is here to help you develop', 'powerful', 'and scalable robotic applications', 'you can use it whenever you want to', 'create a robot software', 'which needs a lot of communication', 'between its', 'sub-programs or has some functionalities', 'that go beyond a very simple use case', 'etc so for a robot', 'that will just open a door with a servo', 'motor when it detects a movement', \"maybe you don't need routes but for a\", 'mobile robot', 'which you want to control with a gps and', 'a camera', 'in this case ross might really help you', \"alright you've just seen what is the why\", 'behind ross', 'and when to use it now what is ross', 'it would be hard to describe exactly', 'what is ross in about two minutes', 'even an hour but here are two main', 'points', 'that will give you an idea of the big', 'picture', 'first of all ross provides you with a', 'way of', 'separating your code into reusable', 'blocks', 'along with a set of communication tools', 'to easily communicate between all your', 'sub-programs', \"let's say that you are programming a\", 'robotic arm', 'you can create a subprogram called', 'node for your camera another for the', 'motion planning', 'another one for the hardware driver', 'another for', 'joystick and so on', 'and each of those independent blocks', 'will communicate', 'between each other in a way that', 'is powerful and scalable', 'the second main point is that ross', 'provides you with many plug-and-play', 'libraries', 'that will save you a huge amount of time', 'and most importantly that will prevent', 'you', 'from reinventing the wheel if we come', 'back to the robotic arm', 'imagine how difficult it can be to', 'compute', 'the inverse kinematic for the arm to', 'plan a trajectory', 'which will make the arm move smoothly', 'and', 'avoid any obstacle on the way', 'impossible you might think unless you', 'spend', 'two years studying mathematics motion', 'planning', 'etc but what if i tell you this', \"you don't need two years you need maybe\", 'two days', 'to install a library and figure out', 'how to use it so you have great', 'communication tools', \"and great libraries that's not all\", 'ros is said to be language agnostic', 'it means that you can program some parts', 'of your application', 'in a programming language and another', 'part', 'in another programming language simply', 'because', \"the communication tools don't rely on a\", 'specific', 'language so in this course we will not', 'go into', 'all the external libraries that exist', 'for many different robots', 'we will mostly focus on the ros basics', 'and core functionalities that will', 'enable you', 'to easily start any robot application', 'powered by ros', 'using python and c plus plus', 'ros is also open source with an', 'active and growing community so', \"you can directly see what's going on you\", 'can get help', 'share your project and even contribute', 'if you wish to all right with this quick', 'introduction', 'you should get some ideas about what is', 'wrong', 'when to use it and why it is useful', \"don't panic though if you don't\", 'understand everything right now', 'the big picture behind ross is pretty', 'hard to get', 'at the beginning but after some practice', 'you will start to get it and i can', 'guarantee you', 'that you will quickly think that ross', 'is awesome']\n"
     ]
    }
   ],
   "source": [
    "# Extract text from transcripts\n",
    "sentences = [i['text'] for i in result['transcript']]\n",
    "print(sentences)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# Chunk sentences together for embedding\n",
    "#TODO: Make this chunking better:Maybe capitalize and fins end of sentences in a better way\n",
    "sentences_in_chunk = 6\n",
    "chunks = []\n",
    "for i in range(0, len(sentences), sentences_in_chunk):\n",
    "    chunks.append(\". \".join(sentences[i:i + sentences_in_chunk]))\n",
    "\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 384)\n"
     ]
    }
   ],
   "source": [
    "# Embed these chunks\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2') # TODO: Pick better models\n",
    "\n",
    "embeddings = model.encode(chunks)\n",
    "embeddings_dict = dict(zip(chunks, embeddings))\n",
    "print(embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings stored into MongoDB\n"
     ]
    }
   ],
   "source": [
    "# Store embeddings in MongoDB\n",
    "# Insert into MongoDB\n",
    "collection = db[\"embeddings\"]   # Collection name\n",
    "document = {\n",
    "    \"source\": \"youtube\",\n",
    "    \"video_id\": video_id,\n",
    "    \"embeddings\": embeddings.tolist()\n",
    "}\n",
    "\n",
    "collection.insert_one(document)\n",
    "print(\"Embeddings stored into MongoDB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Do further preprocessing to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Similarity search using qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from torchvision.transforms import Resize\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "qdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance, for testing, CI/CD\n",
    "\n",
    "#Create a collection or database of texts where you store the embeddings\n",
    "my_collection = \"text_collection\"\n",
    "\n",
    "qdrant.create_collection(\n",
    "    collection_name=my_collection,\n",
    "    vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE)\n",
    ")\n",
    "\n",
    "# Insert embeddings into Qdrant\n",
    "for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "    qdrant.upsert(\n",
    "        collection_name=my_collection,\n",
    "        points=[models.PointStruct(\n",
    "            id=i,\n",
    "            vector=embedding,\n",
    "            payload={\"text\": chunk}\n",
    "        )]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant.count(\n",
    "    collection_name=my_collection,\n",
    "    exact=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity test\n",
    "sample_sentence = \"What is the meaning of life?\"\n",
    "sample_embedding = model.encode(sample_sentence)\n",
    "search_result = qdrant.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=sample_embedding,\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=21, version=0, score=0.1516602337360382, payload={'text': \"and great libraries that's not all. ros is said to be language agnostic. it means that you can program some parts. of your application. in a programming language and another. part\"}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=10, version=0, score=0.07326249778270721, payload={'text': 'create a robot software. which needs a lot of communication. between its. sub-programs or has some functionalities. that go beyond a very simple use case. etc so for a robot'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=0, version=0, score=0.06109253689646721, payload={'text': 'what is the common point between all. those robots. well all the robots you see here are. or can be powered by rouse. roth means robot operating system. it is something between a middleware'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=22, version=0, score=0.05160970240831375, payload={'text': \"in another programming language simply. because. the communication tools don't rely on a. specific. language so in this course we will not. go into\"}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=4, version=0, score=0.05022658780217171, payload={'text': \"understand. the code of any robot. but is that it no another. philosophy behind ross is don't reinvent. the wheel reinventing the wheel is a. very common problem\"}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 24 GB\n"
     ]
    }
   ],
   "source": [
    "# Get GPU available memory\n",
    "import torch\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
    "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35aaec54f3d47d5b6802f9fcfca4d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_quantization_config = True\n",
    "model_id = \"TheBloke/CapybaraHermes-2.5-Mistral-7B-GPTQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using attention implementation: sdpa\n",
      "[INFO] Using model_id: TheBloke/CapybaraHermes-2.5-Mistral-7B-GPTQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\envs\\ai\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\harsh\\.cache\\huggingface\\hub\\models--TheBloke--CapybaraHermes-2.5-Mistral-7B-GPTQ. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "c:\\Users\\harsh\\anaconda3\\envs\\ai\\lib\\site-packages\\transformers\\modeling_utils.py:5006: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "Some weights of the model checkpoint at TheBloke/CapybaraHermes-2.5-Mistral-7B-GPTQ were not used when initializing MistralForCausalLM: ['model.layers.0.mlp.down_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.bias']\n",
      "- This IS expected if you are initializing MistralForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MistralForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils import is_flash_attn_2_available \n",
    "\n",
    "# 1. Create quantization config for smaller model loading (optional)\n",
    "# Requires !pip install bitsandbytes accelerate, see: https://github.com/TimDettmers/bitsandbytes, https://huggingface.co/docs/accelerate/\n",
    "# For models that require 4-bit quantization (use this if you have low GPU memory available)\n",
    "from transformers import BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "# Bonus: Setup Flash Attention 2 for faster inference, default to \"sdpa\" or \"scaled dot product attention\" if it's not available\n",
    "# Flash Attention 2 requires NVIDIA GPU compute capability of 8.0 or above, see: https://developer.nvidia.com/cuda-gpus\n",
    "# Requires !pip install flash-attn, see: https://github.com/Dao-AILab/flash-attention \n",
    "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
    "  attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "  attn_implementation = \"sdpa\"\n",
    "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
    "\n",
    "# 2. Pick a model we'd like to use (this will depend on how much GPU memory you have available)\n",
    "# model_id = \"google/gemma-7b-it\"\n",
    "model_id = model_id # (we already set this above)\n",
    "print(f\"[INFO] Using model_id: {model_id}\")\n",
    "\n",
    "# 3. Instantiate tokenizer (tokenizer turns text into numbers ready for the model) \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "\n",
    "# 4. Instantiate the model\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=\"main\")\n",
    "# llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id)\n",
    "\n",
    "if not use_quantization_config: # quantization takes care of device setting automatically, so if it's not used, send model to GPU \n",
    "    llm_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32002, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "          (k_proj): QuantLinear()\n",
       "          (o_proj): QuantLinear()\n",
       "          (q_proj): QuantLinear()\n",
       "          (v_proj): QuantLinear()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (act_fn): SiLU()\n",
       "          (down_proj): QuantLinear()\n",
       "          (gate_proj): QuantLinear()\n",
       "          (up_proj): QuantLinear()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32002, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model.eval() # put model in evaluation mode\n",
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262426624"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_num_params(model: torch.nn.Module):\n",
    "    return sum([param.numel() for param in model.parameters()])\n",
    "\n",
    "get_model_num_params(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_mem_bytes': 4155817984, 'model_mem_mb': 3963.3, 'model_mem_gb': 3.87}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_mem_size(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Get how much memory a PyTorch model takes up.\n",
    "\n",
    "    See: https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822\n",
    "    \"\"\"\n",
    "    # Get model parameters and buffer sizes\n",
    "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
    "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
    "\n",
    "    # Calculate various model sizes\n",
    "    model_mem_bytes = mem_params + mem_buffers # in bytes\n",
    "    model_mem_mb = model_mem_bytes / (1024**2) # in megabytes\n",
    "    model_mem_gb = model_mem_bytes / (1024**3) # in gigabytes\n",
    "\n",
    "    return {\"model_mem_bytes\": model_mem_bytes,\n",
    "            \"model_mem_mb\": round(model_mem_mb, 2),\n",
    "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
    "\n",
    "get_model_mem_size(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "What is ros?\n",
      "\n",
      "Prompt (formatted):\n",
      "<|im_start|>user\n",
      "What is ros?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What is ros?\"\n",
    "print(f\"Input text:\\n{input_text}\")\n",
    "\n",
    "\n",
    "# Create prompt template for instruction-tuned model\n",
    "dialogue_template = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": input_text}\n",
    "]\n",
    "\n",
    "# Apply the chat template\n",
    "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                       tokenize=False, # keep as raw text (not tokenized)\n",
    "                                       add_generation_prompt=True)\n",
    "print(f\"\\nPrompt (formatted):\\n{prompt}\")\n",
    "\n",
    "# # Tokenize the input text\n",
    "# input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "# print(f\"Input IDs:\\n{input_ids}\")\n",
    "\n",
    "# prompt = input_text #TODO: Fix a prompt structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input (tokenized):\n",
      "{'input_ids': tensor([[    1, 32001,  2188,    13,  3195,   349,   712, 28713, 28804, 32000,\n",
      "         28705,    13, 32001, 13892,    13]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "\n",
      "Model output (tokens):\n",
      "tensor([    1, 32001,  2188,    13,  3195,   349,   712, 28713, 28804, 32000,\n",
      "        28705,    13, 32001, 13892,    13,  1594, 28735, 28725,   442,   272,\n",
      "         5776,   322,  6692,  1077,  2135, 28725,   349,   264,   808,   302,\n",
      "         3930, 24133,   304,  7040,  6202,   486,   272,  5776,   322,  1063,\n",
      "         5926,   438, 28116,  2900, 28723,   661,   349,   396,  1565, 28733,\n",
      "         1394, 10782,   369,  5312,   272,  4892,  3930, 14461,   354,   272,\n",
      "         4099, 28725,  2602, 28725,   304,  5225,   302,  7006,  1649, 28723,\n",
      "           13,    13,  1594, 28735,  5976, 17892,   298,  5061,  2231,  4630,\n",
      "        28725, 16458, 28725,   304,  9096, 18401,  3930,   486,  7501,   264,\n",
      "         5335,  2819,   302, 14573,  1218, 28725,  2490, 13218,  6303, 15901,\n",
      "        28725,  1486, 28733,  4404, 18539, 28725,   304,   264,  6677,   302,\n",
      "         7040,   354,  3667, 28725,  8260, 28725,   304, 15258,   288, 18401,\n",
      "         3930, 28723,   661,   835, 13031,   279,  1002,   272, 14678,   302,\n",
      "         4118, 13218,  8076, 28725,  1259,   390, 27810, 28725,   960, 28718,\n",
      "         3117, 28725,   304,  6074,  8021,  4918, 28725,   778,   264,   521,\n",
      "         1799,  3930, 10782, 28723,    13,    13,  1014,  2191,  8076,   302,\n",
      "          399,  3843,  3024, 28747,    13,    13, 28740, 28723,   399,  3843,\n",
      "        12197, 28747,   851,  5532,   272, 11854,  8076,   369,  8234,  8520,\n",
      "         1444,  9249, 28725,  1259,   390,   272,   399,  3843,  2928,  9720,\n",
      "         1587, 28725,   272,   399,  3843,  5621,  5116, 28725,   304,   272,\n",
      "          399,  3843,  5968,  3179, 28723,    13,    13, 28750, 28723,   399,\n",
      "         3843,   351,  9251, 28747,  2957,   460,   272,  1178, 11294,  1307,\n",
      "          354,  8520,  1444,  9249, 28723,  1306,   460,  3684,   298,   334,\n",
      "         1680,  1758, 28713,   442, 21366,   281,  3033,  4838,   304,   541,\n",
      "          347,  5061,  4057,   304,  1307,   486, 17892, 28723,    13,    13,\n",
      "        28770, 28723,   399,  3843, 11676,  1291, 28747,  2957,   460, 18430,\n",
      "          302,  5202,   399,  3843,  9249, 28725,  8570, 28725,   304,   799,\n",
      "         5823], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text (turn it into numbers) and send it to GPU\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
    "\n",
    "# Generate outputs passed on the tokenized input\n",
    "# See generate docs: https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/text_generation#transformers.GenerationConfig \n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             max_new_tokens=256) # define the maximum number of new tokens to create\n",
    "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (decoded):\n",
      "<s><|im_start|> user\n",
      "What is ros?<|im_end|> \n",
      "<|im_start|> assistant\n",
      "ROS, or the Robot Operating System, is a set of software libraries and tools developed by the Robotics Group at Stanford University. It is an open-source framework that provides the necessary software infrastructure for the development, control, and operation of robots.\n",
      "\n",
      "ROS allows developers to easily create complex, robust, and efficient robot software by providing a wide range of functionalities, including hardware driver modules, high-level algorithms, and a variety of tools for building, testing, and deploying robot software. It also facilitates the integration of various hardware components, such as sensors, actuators, and computer vision systems, into a unified software framework.\n",
      "\n",
      "The main components of ROS include:\n",
      "\n",
      "1. ROS Core: This includes the fundamental components that enable communication between nodes, such as the ROS message passing system, the ROS parameter server, and the ROS master node.\n",
      "\n",
      "2. ROS Messages: These are the data structures used for communication between nodes. They are similar to C++ structs or Python dictionaries and can be easily defined and used by developers.\n",
      "\n",
      "3. ROS Packages: These are collections of related ROS nodes, messages, and other resources\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode the output tokens to text\n",
    "outputs_decoded = tokenizer.decode(outputs[0])\n",
    "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s><|im_start|> user\\nWhat is ros?<|im_end|> \\n<|im_start|> assistant\\nROS, or the Robot Operating System, is a set of software libraries and tools developed by the Robotics Group at Stanford University. It is an open-source framework that provides the necessary software infrastructure for the development, control, and operation of robots.\\n\\nROS allows developers to easily create complex, robust, and efficient robot software by providing a wide range of functionalities, including hardware driver modules, high-level algorithms, and a variety of tools for building, testing, and deploying robot software. It also facilitates the integration of various hardware components, such as sensors, actuators, and computer vision systems, into a unified software framework.\\n\\nThe main components of ROS include:\\n\\n1. ROS Core: This includes the fundamental components that enable communication between nodes, such as the ROS message passing system, the ROS parameter server, and the ROS master node.\\n\\n2. ROS Messages: These are the data structures used for communication between nodes. They are similar to C++ structs or Python dictionaries and can be easily defined and used by developers.\\n\\n3. ROS Packages: These are collections of related ROS nodes, messages, and other resources'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_decoded\n",
    "clean_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: What is ros?\n",
      "\n",
      "Output text:\n",
      "<s><|im_start|> user\n",
      "What is ros?<|im_end|> \n",
      "<|im_start|> assistant\n",
      "ROS, or the Robot Operating System, is a set of software libraries and tools developed by the Robotics Group at Stanford University. It is an open-source framework that provides the necessary software infrastructure for the development, control, and operation of robots.\n",
      "\n",
      "ROS allows developers to easily create complex, robust, and efficient robot software by providing a wide range of functionalities, including hardware driver modules, high-level algorithms, and a variety of tools for building, testing, and deploying robot software. It also facilitates the integration of various hardware components, such as sensors, actuators, and computer vision systems, into a unified software framework.\n",
      "\n",
      "The main components of ROS include:\n",
      "\n",
      "1. ROS Core: This includes the fundamental components that enable communication between nodes, such as the ROS message passing system, the ROS parameter server, and the ROS master node.\n",
      "\n",
      "2. ROS Messages: These are the data structures used for communication between nodes. They are similar to C++ structs or Python dictionaries and can be easily defined and used by developers.\n",
      "\n",
      "3. ROS Packages: These are collections of related ROS nodes, messages, and other resources\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input text: {input_text}\\n\")\n",
    "print(f\"Output text:\\n{outputs_decoded.replace(prompt, '').replace('<bos>', '').replace('<eos>', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nutrition-style questions generated with GPT4\n",
    "gpt4_questions = [\n",
    "    \"WWhat are the main differences between ROS 1 and ROS 2?\",\n",
    "    \"Explain the concept of topics, services, and actions in ROS.\",\n",
    "    \"What is the purpose of the catkin_make command in ROS 1?\",\n",
    "    \"What is the function of rviz in ROS?\",\n",
    "    \"What is the purpose of rqt_graph, and how can it help in debugging a ROS system?\"\n",
    "] \n",
    "\n",
    "# Manually created question list\n",
    "manual_questions = [\n",
    "    \"What is ros?\",\n",
    "]\n",
    "\n",
    "query_list = gpt4_questions + manual_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is ros?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "query = random.choice(query_list)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = qdrant.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=model.encode(query),\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and great libraries that's not all. ros is said to be language agnostic. it means that you can program some parts. of your application. in a programming language and another. part\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result[0].payload['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Similarity Search and LLM output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(query: str, \n",
    "                     context_items: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Augments query with text-based context from context_items.\n",
    "    \"\"\"\n",
    "    # Join context items into one dotted paragraph\n",
    "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
    "\n",
    "    # Create a base prompt with examples to help the model\n",
    "    # Note: this is very customizable, I've chosen to use 3 examples of the answer style we'd like.\n",
    "    # We could also write this in a txt file and import it in if we wanted.\n",
    "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
    "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
    "Don't return the thinking, only return the answer.\n",
    "Make sure your answers are as explanatory as possible.\n",
    "Use the following examples as reference for the ideal answer style.\n",
    "\\nExample 1:\n",
    "Query: What are the fat-soluble vitamins?\n",
    "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
    "\\nExample 2:\n",
    "Query: What are the causes of type 2 diabetes?\n",
    "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
    "\\nExample 3:\n",
    "Query: What is the importance of hydration for physical performance?\n",
    "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
    "\\nNow use the following context items to answer the user query:\n",
    "{context}\n",
    "\\nRelevant passages: <extract relevant passages from the context here>\n",
    "User query: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Update base prompt with context items and query   \n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "\n",
    "    # Create prompt template for instruction-tuned model\n",
    "    dialogue_template = [\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": base_prompt}\n",
    "    ]\n",
    "\n",
    "    # Apply the chat template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                          tokenize=False,\n",
    "                                          add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the function of rviz in ROS?\n",
      "<|im_start|>user\n",
      "Based on the following context items, please answer the query.\n",
      "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
      "Don't return the thinking, only return the answer.\n",
      "Make sure your answers are as explanatory as possible.\n",
      "Use the following examples as reference for the ideal answer style.\n",
      "\n",
      "Example 1:\n",
      "Query: What are the fat-soluble vitamins?\n",
      "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
      "\n",
      "Example 2:\n",
      "Query: What are the causes of type 2 diabetes?\n",
      "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
      "\n",
      "Example 3:\n",
      "Query: What is the importance of hydration for physical performance?\n",
      "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
      "\n",
      "Now use the following context items to answer the user query:\n",
      "- and great libraries that's not all. ros is said to be language agnostic. it means that you can program some parts. of your application. in a programming language and another. part\n",
      "- powered by ros. using python and c plus plus. ros is also open source with an. active and growing community so. you can directly see what's going on you. can get help\n",
      "- and a framework built especially for. robotics applications rao's goal. is to provide a standard for robotic. software. that developers can use and reuse in. any robot once you know how to use ros\n",
      "- so this is the why behind ross. now when to use ros maybe. you've already started to program robots. with. an arduino board with a custom code. on a computer and what you will quickly\n",
      "- all the external libraries that exist. for many different robots. we will mostly focus on the ros basics. and core functionalities that will. enable you. to easily start any robot application\n",
      "\n",
      "Relevant passages: <extract relevant passages from the context here>\n",
      "User query: What is the function of rviz in ROS?\n",
      "Answer:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import random\n",
    "query = random.choice(query_list)\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Get relevant resources\n",
    "# scores, indices = retrieve_relevant_resources(query=query,\n",
    "#                                               embeddings=embeddings)\n",
    "search_results = qdrant.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=model.encode(query),\n",
    "    limit=5\n",
    ")\n",
    "    \n",
    "# Create a list of context items\n",
    "# context_items = [pages_and_chunks[i] for i in indices]\n",
    "context_items = []\n",
    "for result in search_results:\n",
    "    context_items.append({\"sentence_chunk\": result.payload['text']})\n",
    "\n",
    "# Format prompt with context items\n",
    "prompt = prompt_formatter(query=query,\n",
    "                          context_items=context_items)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the function of rviz in ROS?\n",
      "RAG answer:\n",
      "<s><|im_start|> user\n",
      "Based on the following context items, please answer the query.\n",
      "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
      "Don't return the thinking, only return the answer.\n",
      "Make sure your answers are as explanatory as possible.\n",
      "Use the following examples as reference for the ideal answer style.\n",
      "\n",
      "Example 1:\n",
      "Query: What are the fat-soluble vitamins?\n",
      "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
      "\n",
      "Example 2:\n",
      "Query: What are the causes of type 2 diabetes?\n",
      "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
      "\n",
      "Example 3:\n",
      "Query: What is the importance of hydration for physical performance?\n",
      "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
      "\n",
      "Now use the following context items to answer the user query:\n",
      "- and great libraries that's not all. ros is said to be language agnostic. it means that you can program some parts. of your application. in a programming language and another. part\n",
      "- powered by ros. using python and c plus plus. ros is also open source with an. active and growing community so. you can directly see what's going on you. can get help\n",
      "- and a framework built especially for. robotics applications rao's goal. is to provide a standard for robotic. software. that developers can use and reuse in. any robot once you know how to use ros\n",
      "- so this is the why behind ross. now when to use ros maybe. you've already started to program robots. with. an arduino board with a custom code. on a computer and what you will quickly\n",
      "- all the external libraries that exist. for many different robots. we will mostly focus on the ros basics. and core functionalities that will. enable you. to easily start any robot application\n",
      "\n",
      "Relevant passages: <extract relevant passages from the context here>\n",
      "User query: What is the function of rviz in ROS?\n",
      "Answer:<|im_end|> \n",
      "<|im_start|> assistant\n",
      "The function of RViz in ROS (Robot Operating System) is to provide a 3D visualization interface for ROS messages. RViz allows users to visualize robot models, sensor data, and trajectories in a 3D environment, enabling users to monitor and control the robot's behavior. It acts as a central tool for visualizing and understanding the data generated by the robot, its sensors, and the environment, which is crucial for robotics applications. By using RViz, users can better understand and debug their robot's behavior and performance.<|im_end|>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m output_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRAG answer:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_text\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(prompt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate an output of tokens\n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             temperature=0.7, # lower temperature = more deterministic outputs, higher temperature = more creative outputs\n",
    "                             do_sample=True, # whether or not to use sampling, see https://huyenchip.com/2024/01/16/sampling.html for more\n",
    "                             max_new_tokens=256) # how many new tokens to generate from prompt \n",
    "\n",
    "# Turn the output tokens into text\n",
    "output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"RAG answer:\\n{output_text}\").replace(prompt, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query, \n",
    "        temperature=0.7,\n",
    "        max_new_tokens=512,\n",
    "        format_answer_text=True, \n",
    "        return_answer_only=True):\n",
    "    \"\"\"\n",
    "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get just the scores and indices of top related results\n",
    "    # scores, indices = retrieve_relevant_resources(query=query,\n",
    "    #                                               embeddings=embeddings)\n",
    "    search_results = qdrant.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=model.encode(query),\n",
    "    limit=5\n",
    ")\n",
    "    \n",
    "    # Create a list of context items\n",
    "    # context_items = [pages_and_chunks[i] for i in indices]\n",
    "    context_items = []\n",
    "    for result in search_results:\n",
    "        context_items.append({\"sentence_chunk\": result.payload['text']})\n",
    "\n",
    "    scores = [result.score for result in search_results]\n",
    "\n",
    "    # Add score to context item\n",
    "    for i, item in enumerate(context_items):\n",
    "        item[\"score\"] = scores[i] # return score back to CPU \n",
    "        \n",
    "    # Format the prompt with context items\n",
    "    prompt = prompt_formatter(query=query,\n",
    "                              context_items=context_items)\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate an output of tokens\n",
    "    outputs = llm_model.generate(**input_ids,\n",
    "                                 temperature=temperature,\n",
    "                                 do_sample=True,\n",
    "                                 max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # Turn the output tokens into text\n",
    "    output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "    if format_answer_text:\n",
    "        # Replace special tokens and unnecessary help message\n",
    "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
    "\n",
    "    # Only return the answer without the context items\n",
    "    if return_answer_only:\n",
    "        return output_text\n",
    "    \n",
    "    return output_text, context_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to print wrapped text \n",
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the purpose of rqt_graph, and how can it help in debugging a ROS system?\n",
      "Answer:\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'print_wrapped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m answer, context_items \u001b[38;5;241m=\u001b[39m ask(query\u001b[38;5;241m=\u001b[39mquery, \n\u001b[0;32m      6\u001b[0m                             temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m      7\u001b[0m                             max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m      8\u001b[0m                             return_answer_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mprint_wrapped\u001b[49m(answer)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext items:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m context_items\n",
      "\u001b[1;31mNameError\u001b[0m: name 'print_wrapped' is not defined"
     ]
    }
   ],
   "source": [
    "query = random.choice(query_list)\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Answer query with context and return context \n",
    "answer, context_items = ask(query=query, \n",
    "                            temperature=0.7,\n",
    "                            max_new_tokens=512,\n",
    "                            return_answer_only=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\n",
      "<s><|im_start|> user Based on the following context items, please answer the\n",
      "query. Give yourself room to think by extracting relevant passages from the\n",
      "context before answering the query. Don't return the thinking, only return the\n",
      "answer. Make sure your answers are as explanatory as possible. Use the following\n",
      "examples as reference for the ideal answer style.  Example 1: Query: What are\n",
      "the fat-soluble vitamins? Answer: The fat-soluble vitamins include Vitamin A,\n",
      "Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats\n",
      "in the diet and can be stored in the body's fatty tissue and liver for later\n",
      "use. Vitamin A is important for vision, immune function, and skin health.\n",
      "Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E\n",
      "acts as an antioxidant, protecting cells from damage. Vitamin K is essential for\n",
      "blood clotting and bone metabolism.  Example 2: Query: What are the causes of\n",
      "type 2 diabetes? Answer: Type 2 diabetes is often associated with overnutrition,\n",
      "particularly the overconsumption of calories leading to obesity. Factors include\n",
      "a diet high in refined sugars and saturated fats, which can lead to insulin\n",
      "resistance, a condition where the body's cells do not respond effectively to\n",
      "insulin. Over time, the pancreas cannot produce enough insulin to manage blood\n",
      "sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric\n",
      "intake without sufficient physical activity exacerbates the risk by promoting\n",
      "weight gain and fat accumulation, particularly around the abdomen, further\n",
      "contributing to insulin resistance.  Example 3: Query: What is the importance of\n",
      "hydration for physical performance? Answer: Hydration is crucial for physical\n",
      "performance because water plays key roles in maintaining blood volume,\n",
      "regulating body temperature, and ensuring the transport of nutrients and oxygen\n",
      "to cells. Adequate hydration is essential for optimal muscle function,\n",
      "endurance, and recovery. Dehydration can lead to decreased performance, fatigue,\n",
      "and increased risk of heat-related illnesses, such as heat stroke. Drinking\n",
      "sufficient water before, during, and after exercise helps ensure peak physical\n",
      "performance and recovery.  Now use the following context items to answer the\n",
      "user query: - powered by ros. using python and c plus plus. ros is also open\n",
      "source with an. active and growing community so. you can directly see what's\n",
      "going on you. can get help - and great libraries that's not all. ros is said to\n",
      "be language agnostic. it means that you can program some parts. of your\n",
      "application. in a programming language and another. part - and a framework built\n",
      "especially for. robotics applications rao's goal. is to provide a standard for\n",
      "robotic. software. that developers can use and reuse in. any robot once you know\n",
      "how to use ros - so this is the why behind ross. now when to use ros maybe.\n",
      "you've already started to program robots. with. an arduino board with a custom\n",
      "code. on a computer and what you will quickly - separating your code into\n",
      "reusable. blocks. along with a set of communication tools. to easily communicate\n",
      "between all your. sub-programs. let's say that you are programming a  Relevant\n",
      "passages: <extract relevant passages from the context here> User query: What is\n",
      "the purpose of rqt_graph, and how can it help in debugging a ROS system?\n",
      "Answer:<|im_end|>  <|im_start|> assistant Rqt_graph is a visualization tool in\n",
      "the ROS (Robot Operating System) ecosystem. It helps visualize the communication\n",
      "and control flow within a ROS system by creating a graph representation of\n",
      "nodes, topics, and messages. This visual representation aids in understanding\n",
      "the system's architecture, identifying communication bottlenecks, and tracing\n",
      "messages between nodes.  In debugging a ROS system, rqt_graph can be\n",
      "particularly useful for identifying the flow of information and spotting any\n",
      "potential issues within the system. By visualizing the communication flow,\n",
      "developers can quickly identify and pinpoint the source of problems, such as\n",
      "messages that are not being published or subscribed to correctly, or nodes that\n",
      "are not functioning as expected. This visualization helps in debugging by\n",
      "providing a clear and concise overview of the system's behavior, making it\n",
      "easier to isolate and resolve issues.<|im_end|>\n",
      "Context items:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sentence_chunk': \"powered by ros. using python and c plus plus. ros is also open source with an. active and growing community so. you can directly see what's going on you. can get help\",\n",
       "  'score': 0.4759140610694885},\n",
       " {'sentence_chunk': \"and great libraries that's not all. ros is said to be language agnostic. it means that you can program some parts. of your application. in a programming language and another. part\",\n",
       "  'score': 0.40794384479522705},\n",
       " {'sentence_chunk': \"and a framework built especially for. robotics applications rao's goal. is to provide a standard for robotic. software. that developers can use and reuse in. any robot once you know how to use ros\",\n",
       "  'score': 0.37814757227897644},\n",
       " {'sentence_chunk': \"so this is the why behind ross. now when to use ros maybe. you've already started to program robots. with. an arduino board with a custom code. on a computer and what you will quickly\",\n",
       "  'score': 0.37660783529281616},\n",
       " {'sentence_chunk': \"separating your code into reusable. blocks. along with a set of communication tools. to easily communicate between all your. sub-programs. let's say that you are programming a\",\n",
       "  'score': 0.3623393177986145}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Answer:\\n\")\n",
    "print_wrapped(answer)\n",
    "print(f\"Context items:\")\n",
    "context_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

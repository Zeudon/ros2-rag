{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the common point between all\n",
      "those robots\n",
      "well all the robots you see here are\n",
      "or can be powered by rouse\n",
      "roth means robot operating system\n",
      "it is something between a middleware\n",
      "and a framework built especially for\n",
      "robotics applications rao's goal\n",
      "is to provide a standard for robotic\n",
      "software\n",
      "that developers can use and reuse in\n",
      "any robot once you know how to use ros\n",
      "efficiently you will be able to set up\n",
      "a new software for a new robot in no\n",
      "time\n",
      "you first need to master the basics and\n",
      "core functionalities\n",
      "which you will see in this course and\n",
      "then\n",
      "for every new robot you program you will\n",
      "gain more skills\n",
      "that can apply to other robots\n",
      "the more you know about ross the easiest\n",
      "it will be for you to program and\n",
      "understand\n",
      "the code of any robot\n",
      "but is that it no another\n",
      "philosophy behind ross is don't reinvent\n",
      "the wheel reinventing the wheel is a\n",
      "very common problem\n",
      "in robotics people always start building\n",
      "new software\n",
      "that is already existing and thus they\n",
      "don't have the time\n",
      "to work on really valuable stuff\n",
      "what if instead you could build on a\n",
      "strong\n",
      "software base to directly program\n",
      "high-level functionalities\n",
      "and work on use cases instead of\n",
      "low-level technical stuff that already\n",
      "exists in way\n",
      "so this is the why behind ross\n",
      "now when to use ros maybe\n",
      "you've already started to program robots\n",
      "with\n",
      "an arduino board with a custom code\n",
      "on a computer and what you will quickly\n",
      "experience\n",
      "is that the more sensors actuators\n",
      "controllers you add on your application\n",
      "the more complex\n",
      "it becomes until you reach a point\n",
      "where everything is mixed up and\n",
      "you can't add any code for a new sensor\n",
      "without having a huge headache\n",
      "ross is here to help you develop\n",
      "powerful\n",
      "and scalable robotic applications\n",
      "you can use it whenever you want to\n",
      "create a robot software\n",
      "which needs a lot of communication\n",
      "between its\n",
      "sub-programs or has some functionalities\n",
      "that go beyond a very simple use case\n",
      "etc so for a robot\n",
      "that will just open a door with a servo\n",
      "motor when it detects a movement\n",
      "maybe you don't need routes but for a\n",
      "mobile robot\n",
      "which you want to control with a gps and\n",
      "a camera\n",
      "in this case ross might really help you\n",
      "alright you've just seen what is the why\n",
      "behind ross\n",
      "and when to use it now what is ross\n",
      "it would be hard to describe exactly\n",
      "what is ross in about two minutes\n",
      "even an hour but here are two main\n",
      "points\n",
      "that will give you an idea of the big\n",
      "picture\n",
      "first of all ross provides you with a\n",
      "way of\n",
      "separating your code into reusable\n",
      "blocks\n",
      "along with a set of communication tools\n",
      "to easily communicate between all your\n",
      "sub-programs\n",
      "let's say that you are programming a\n",
      "robotic arm\n",
      "you can create a subprogram called\n",
      "node for your camera another for the\n",
      "motion planning\n",
      "another one for the hardware driver\n",
      "another for\n",
      "joystick and so on\n",
      "and each of those independent blocks\n",
      "will communicate\n",
      "between each other in a way that\n",
      "is powerful and scalable\n",
      "the second main point is that ross\n",
      "provides you with many plug-and-play\n",
      "libraries\n",
      "that will save you a huge amount of time\n",
      "and most importantly that will prevent\n",
      "you\n",
      "from reinventing the wheel if we come\n",
      "back to the robotic arm\n",
      "imagine how difficult it can be to\n",
      "compute\n",
      "the inverse kinematic for the arm to\n",
      "plan a trajectory\n",
      "which will make the arm move smoothly\n",
      "and\n",
      "avoid any obstacle on the way\n",
      "impossible you might think unless you\n",
      "spend\n",
      "two years studying mathematics motion\n",
      "planning\n",
      "etc but what if i tell you this\n",
      "you don't need two years you need maybe\n",
      "two days\n",
      "to install a library and figure out\n",
      "how to use it so you have great\n",
      "communication tools\n",
      "and great libraries that's not all\n",
      "ros is said to be language agnostic\n",
      "it means that you can program some parts\n",
      "of your application\n",
      "in a programming language and another\n",
      "part\n",
      "in another programming language simply\n",
      "because\n",
      "the communication tools don't rely on a\n",
      "specific\n",
      "language so in this course we will not\n",
      "go into\n",
      "all the external libraries that exist\n",
      "for many different robots\n",
      "we will mostly focus on the ros basics\n",
      "and core functionalities that will\n",
      "enable you\n",
      "to easily start any robot application\n",
      "powered by ros\n",
      "using python and c plus plus\n",
      "ros is also open source with an\n",
      "active and growing community so\n",
      "you can directly see what's going on you\n",
      "can get help\n",
      "share your project and even contribute\n",
      "if you wish to all right with this quick\n",
      "introduction\n",
      "you should get some ideas about what is\n",
      "wrong\n",
      "when to use it and why it is useful\n",
      "don't panic though if you don't\n",
      "understand everything right now\n",
      "the big picture behind ross is pretty\n",
      "hard to get\n",
      "at the beginning but after some practice\n",
      "you will start to get it and i can\n",
      "guarantee you\n",
      "that you will quickly think that ross\n",
      "is awesome\n"
     ]
    }
   ],
   "source": [
    "def get_youtube_transcript(video_url: str) -> list:\n",
    "    video_id = video_url.split(\"v=\")[1]\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    return transcript\n",
    "video_url = \"https://www.youtube.com/watch?v=8QfI5a7lTKU\"\n",
    "video_id = video_url.split(\"v=\")[1]\n",
    "\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "for segment in transcript:\n",
    "    print(segment['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript stored into MongoDB\n"
     ]
    }
   ],
   "source": [
    "## MongoDB\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")  # Replace with your MongoDB connection string\n",
    "db = client[\"youtube_database\"]  # Database name\n",
    "collection = db[\"transcripts\"]   # Collection name\n",
    "\n",
    "# Insert into MongoDB\n",
    "document = {\n",
    "    \"source\": \"youtube\",\n",
    "    \"video_id\": video_id,\n",
    "    \"transcript\": transcript\n",
    "}\n",
    "\n",
    "collection.insert_one(document)\n",
    "print(\"Transcript stored into MongoDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_id', 'source', 'video_id', 'transcript'])\n"
     ]
    }
   ],
   "source": [
    "result = collection.find_one({\"video_id\": video_id})\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what is the common point between all', 'those robots', 'well all the robots you see here are', 'or can be powered by rouse', 'roth means robot operating system', 'it is something between a middleware', 'and a framework built especially for', \"robotics applications rao's goal\", 'is to provide a standard for robotic', 'software', 'that developers can use and reuse in', 'any robot once you know how to use ros', 'efficiently you will be able to set up', 'a new software for a new robot in no', 'time', 'you first need to master the basics and', 'core functionalities', 'which you will see in this course and', 'then', 'for every new robot you program you will', 'gain more skills', 'that can apply to other robots', 'the more you know about ross the easiest', 'it will be for you to program and', 'understand', 'the code of any robot', 'but is that it no another', \"philosophy behind ross is don't reinvent\", 'the wheel reinventing the wheel is a', 'very common problem', 'in robotics people always start building', 'new software', 'that is already existing and thus they', \"don't have the time\", 'to work on really valuable stuff', 'what if instead you could build on a', 'strong', 'software base to directly program', 'high-level functionalities', 'and work on use cases instead of', 'low-level technical stuff that already', 'exists in way', 'so this is the why behind ross', 'now when to use ros maybe', \"you've already started to program robots\", 'with', 'an arduino board with a custom code', 'on a computer and what you will quickly', 'experience', 'is that the more sensors actuators', 'controllers you add on your application', 'the more complex', 'it becomes until you reach a point', 'where everything is mixed up and', \"you can't add any code for a new sensor\", 'without having a huge headache', 'ross is here to help you develop', 'powerful', 'and scalable robotic applications', 'you can use it whenever you want to', 'create a robot software', 'which needs a lot of communication', 'between its', 'sub-programs or has some functionalities', 'that go beyond a very simple use case', 'etc so for a robot', 'that will just open a door with a servo', 'motor when it detects a movement', \"maybe you don't need routes but for a\", 'mobile robot', 'which you want to control with a gps and', 'a camera', 'in this case ross might really help you', \"alright you've just seen what is the why\", 'behind ross', 'and when to use it now what is ross', 'it would be hard to describe exactly', 'what is ross in about two minutes', 'even an hour but here are two main', 'points', 'that will give you an idea of the big', 'picture', 'first of all ross provides you with a', 'way of', 'separating your code into reusable', 'blocks', 'along with a set of communication tools', 'to easily communicate between all your', 'sub-programs', \"let's say that you are programming a\", 'robotic arm', 'you can create a subprogram called', 'node for your camera another for the', 'motion planning', 'another one for the hardware driver', 'another for', 'joystick and so on', 'and each of those independent blocks', 'will communicate', 'between each other in a way that', 'is powerful and scalable', 'the second main point is that ross', 'provides you with many plug-and-play', 'libraries', 'that will save you a huge amount of time', 'and most importantly that will prevent', 'you', 'from reinventing the wheel if we come', 'back to the robotic arm', 'imagine how difficult it can be to', 'compute', 'the inverse kinematic for the arm to', 'plan a trajectory', 'which will make the arm move smoothly', 'and', 'avoid any obstacle on the way', 'impossible you might think unless you', 'spend', 'two years studying mathematics motion', 'planning', 'etc but what if i tell you this', \"you don't need two years you need maybe\", 'two days', 'to install a library and figure out', 'how to use it so you have great', 'communication tools', \"and great libraries that's not all\", 'ros is said to be language agnostic', 'it means that you can program some parts', 'of your application', 'in a programming language and another', 'part', 'in another programming language simply', 'because', \"the communication tools don't rely on a\", 'specific', 'language so in this course we will not', 'go into', 'all the external libraries that exist', 'for many different robots', 'we will mostly focus on the ros basics', 'and core functionalities that will', 'enable you', 'to easily start any robot application', 'powered by ros', 'using python and c plus plus', 'ros is also open source with an', 'active and growing community so', \"you can directly see what's going on you\", 'can get help', 'share your project and even contribute', 'if you wish to all right with this quick', 'introduction', 'you should get some ideas about what is', 'wrong', 'when to use it and why it is useful', \"don't panic though if you don't\", 'understand everything right now', 'the big picture behind ross is pretty', 'hard to get', 'at the beginning but after some practice', 'you will start to get it and i can', 'guarantee you', 'that you will quickly think that ross', 'is awesome']\n"
     ]
    }
   ],
   "source": [
    "# Extract text from transcripts\n",
    "sentences = [i['text'] for i in result['transcript']]\n",
    "print(sentences)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# Chunk sentences together for embedding\n",
    "#TODO: Make this chunking better:Maybe capitalize and fins end of sentences in a better way\n",
    "sentences_in_chunk = 6\n",
    "chunks = []\n",
    "for i in range(0, len(sentences), sentences_in_chunk):\n",
    "    chunks.append(\". \".join(sentences[i:i + sentences_in_chunk]))\n",
    "\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 384)\n"
     ]
    }
   ],
   "source": [
    "# Embed these chunks\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2') # TODO: Pick better models\n",
    "\n",
    "embeddings = model.encode(chunks)\n",
    "embeddings_dict = dict(zip(chunks, embeddings))\n",
    "print(embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings stored into MongoDB\n"
     ]
    }
   ],
   "source": [
    "# Store embeddings in MongoDB\n",
    "# Insert into MongoDB\n",
    "collection = db[\"embeddings\"]   # Collection name\n",
    "document = {\n",
    "    \"source\": \"youtube\",\n",
    "    \"video_id\": video_id,\n",
    "    \"embeddings\": embeddings.tolist()\n",
    "}\n",
    "\n",
    "collection.insert_one(document)\n",
    "print(\"Embeddings stored into MongoDB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Do further preprocessing to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Similarity search using qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from torchvision.transforms import Resize\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "qdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance, for testing, CI/CD\n",
    "\n",
    "#Create a collection or database of texts where you store the embeddings\n",
    "my_collection = \"text_collection\"\n",
    "\n",
    "qdrant.create_collection(\n",
    "    collection_name=my_collection,\n",
    "    vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE)\n",
    ")\n",
    "\n",
    "# Insert embeddings into Qdrant\n",
    "for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "    qdrant.upsert(\n",
    "        collection_name=my_collection,\n",
    "        points=[models.PointStruct(\n",
    "            id=i,\n",
    "            vector=embedding,\n",
    "            payload={\"text\": chunk}\n",
    "        )]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant.count(\n",
    "    collection_name=my_collection,\n",
    "    exact=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity test\n",
    "sample_sentence = \"What is the meaning of life?\"\n",
    "sample_embedding = model.encode(sample_sentence)\n",
    "search_result = qdrant.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=sample_embedding,\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=21, version=0, score=0.1516602337360382, payload={'text': \"and great libraries that's not all. ros is said to be language agnostic. it means that you can program some parts. of your application. in a programming language and another. part\"}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=10, version=0, score=0.07326249778270721, payload={'text': 'create a robot software. which needs a lot of communication. between its. sub-programs or has some functionalities. that go beyond a very simple use case. etc so for a robot'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=0, version=0, score=0.06109253689646721, payload={'text': 'what is the common point between all. those robots. well all the robots you see here are. or can be powered by rouse. roth means robot operating system. it is something between a middleware'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=22, version=0, score=0.05160970240831375, payload={'text': \"in another programming language simply. because. the communication tools don't rely on a. specific. language so in this course we will not. go into\"}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=4, version=0, score=0.05022658780217171, payload={'text': \"understand. the code of any robot. but is that it no another. philosophy behind ross is don't reinvent. the wheel reinventing the wheel is a. very common problem\"}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 24 GB\n"
     ]
    }
   ],
   "source": [
    "# Get GPU available memory\n",
    "import torch\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
    "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a55ba29e9cd4c12a50443fc95e5027d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_quantization_config = True\n",
    "model_id = \"TheBloke/CapybaraHermes-2.5-Mistral-7B-GPTQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using attention implementation: sdpa\n",
      "[INFO] Using model_id: TheBloke/CapybaraHermes-2.5-Mistral-7B-GPTQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "c:\\Users\\harsh\\anaconda3\\envs\\ai\\lib\\site-packages\\transformers\\modeling_utils.py:5006: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "Some weights of the model checkpoint at TheBloke/CapybaraHermes-2.5-Mistral-7B-GPTQ were not used when initializing MistralForCausalLM: ['model.layers.0.mlp.down_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.bias']\n",
      "- This IS expected if you are initializing MistralForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MistralForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils import is_flash_attn_2_available \n",
    "\n",
    "# 1. Create quantization config for smaller model loading (optional)\n",
    "# Requires !pip install bitsandbytes accelerate, see: https://github.com/TimDettmers/bitsandbytes, https://huggingface.co/docs/accelerate/\n",
    "# For models that require 4-bit quantization (use this if you have low GPU memory available)\n",
    "from transformers import BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "# Bonus: Setup Flash Attention 2 for faster inference, default to \"sdpa\" or \"scaled dot product attention\" if it's not available\n",
    "# Flash Attention 2 requires NVIDIA GPU compute capability of 8.0 or above, see: https://developer.nvidia.com/cuda-gpus\n",
    "# Requires !pip install flash-attn, see: https://github.com/Dao-AILab/flash-attention \n",
    "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
    "  attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "  attn_implementation = \"sdpa\"\n",
    "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
    "\n",
    "# 2. Pick a model we'd like to use (this will depend on how much GPU memory you have available)\n",
    "# model_id = \"google/gemma-7b-it\"\n",
    "model_id = model_id # (we already set this above)\n",
    "print(f\"[INFO] Using model_id: {model_id}\")\n",
    "\n",
    "# 3. Instantiate tokenizer (tokenizer turns text into numbers ready for the model) \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "\n",
    "# 4. Instantiate the model\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=\"main\")\n",
    "# llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id)\n",
    "\n",
    "if not use_quantization_config: # quantization takes care of device setting automatically, so if it's not used, send model to GPU \n",
    "    llm_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32002, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "          (k_proj): QuantLinear()\n",
       "          (o_proj): QuantLinear()\n",
       "          (q_proj): QuantLinear()\n",
       "          (v_proj): QuantLinear()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (act_fn): SiLU()\n",
       "          (down_proj): QuantLinear()\n",
       "          (gate_proj): QuantLinear()\n",
       "          (up_proj): QuantLinear()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32002, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model.eval() # put model in evaluation mode\n",
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262426624"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_num_params(model: torch.nn.Module):\n",
    "    return sum([param.numel() for param in model.parameters()])\n",
    "\n",
    "get_model_num_params(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_mem_bytes': 4155817984, 'model_mem_mb': 3963.3, 'model_mem_gb': 3.87}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_mem_size(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Get how much memory a PyTorch model takes up.\n",
    "\n",
    "    See: https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822\n",
    "    \"\"\"\n",
    "    # Get model parameters and buffer sizes\n",
    "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
    "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
    "\n",
    "    # Calculate various model sizes\n",
    "    model_mem_bytes = mem_params + mem_buffers # in bytes\n",
    "    model_mem_mb = model_mem_bytes / (1024**2) # in megabytes\n",
    "    model_mem_gb = model_mem_bytes / (1024**3) # in gigabytes\n",
    "\n",
    "    return {\"model_mem_bytes\": model_mem_bytes,\n",
    "            \"model_mem_mb\": round(model_mem_mb, 2),\n",
    "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
    "\n",
    "get_model_mem_size(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "What is ros?\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What is ros?\"\n",
    "print(f\"Input text:\\n{input_text}\")\n",
    "\n",
    "system_message = \"You are a robotic operating system (ROS) developer\"\n",
    "\n",
    "# Create prompt template for instruction-tuned model\n",
    "dialogue_template = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": input_text}\n",
    "]\n",
    "\n",
    "prompt=f'''<|im_start|>system\n",
    "{system_message}<|im_end|>\n",
    "<|im_start|>user\n",
    "{input_text}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "'''\n",
    "\n",
    "# Apply the chat template\n",
    "# prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "#                                        tokenize=False, # keep as raw text (not tokenized)\n",
    "#                                        add_generation_prompt=True)\n",
    "# print(f\"\\nPrompt (formatted):\\n{prompt}\")\n",
    "\n",
    "# # Tokenize the input text\n",
    "# input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "# print(f\"Input IDs:\\n{input_ids}\")\n",
    "\n",
    "# prompt = input_text #TODO: Fix a prompt structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a robotic operating system (ROS) developer<|im_end|>\\n<|im_start|>user\\nWhat is ros?<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input (tokenized):\n",
      "{'input_ids': tensor([[    1, 32001,  1587,    13,  1976,   460,   264,  7006,  7839, 10513,\n",
      "          1587,   325,  1594, 28735, 28731, 21782, 32000, 28705,    13, 32001,\n",
      "          2188,    13,  3195,   349,   712, 28713, 28804, 32000, 28705,    13,\n",
      "         32001, 13892,    13]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "\n",
      "Model output (tokens):\n",
      "tensor([    1, 32001,  1587,    13,  1976,   460,   264,  7006,  7839, 10513,\n",
      "         1587,   325,  1594, 28735, 28731, 21782, 32000, 28705,    13, 32001,\n",
      "         2188,    13,  3195,   349,   712, 28713, 28804, 32000, 28705,    13,\n",
      "        32001, 13892,    13,  1594, 28735, 28725,   442,  5776,   322,  6692,\n",
      "         1077,  2135, 28725,   349,   396,  1565, 28733,  1394, 28725, 11678,\n",
      "        28733,  3015,  1077,  1587, 13395,  5682,   354,   272,  4099,   304,\n",
      "        12364,   302, 18401,  1063,  8429, 28723,   661,  5312,   264, 17574,\n",
      "        28725,   968,  1098, 10782,   298,  1950, 28725, 28618, 28725,   304,\n",
      "         9087,  4118,  8076,   302,   264, 18401, 28742, 28713,  3930,  7232,\n",
      "        28725,  1259,   390, 20968, 28725,  1862,  1837, 28725,  8036,  7394,\n",
      "        28725,   304,  5161, 28733, 14727, 28723,    13,    13,  1594, 28735,\n",
      "        12335,   302,   264,   808,   302,  7040, 28725, 24133, 28725,   304,\n",
      "        12368,   594,   369, 25729,   272,  9313,   302,  4630, 28725,   968,\n",
      "         1098, 18401,  1063,  3930,  4918, 28723,   661,  5976, 17892,   298,\n",
      "         5061,   312,  1730,  2696, 28725, 28618,   633, 18539, 28725,   304,\n",
      "         8248,   380,   356, 18401,  1063,  7028, 28723,    13,    13,  2064,\n",
      "         4190,   302,   399,  3843,  3024,   264,  2928, 28733,  4119,   288,\n",
      "         1587,   354,   791, 28733,  5226,  8520, 28725,   264,  3660,  5411,\n",
      "         1587, 28725,   264,   808,   302,  7040,   354,  3667,   304,  3822,\n",
      "        18401,  8429, 28725,   304,   264,  2475,  5442,   302,   710, 28733,\n",
      "        12747, 17948,   354,  4118, 18401,  1063,  9796, 28723,    13,    13,\n",
      "          657, 14060, 28725,   399,  3843,   349,   264,  6787, 28725, 17574,\n",
      "        28725,   304,  1565, 28733,  1394,  3921,   369,  9878,  8961,   272,\n",
      "         4099,   304, 12364,   302, 18401,  1063,  3930,  8429, 28725, 25748,\n",
      "        15334, 28725, 22488, 28725,   304, 18185, 10617,   298,  3232,   356,\n",
      "          652,  6421,  4418,   304,  8248,   380,   680, 23463, 28723, 32000],\n",
      "       device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text (turn it into numbers) and send it to GPU\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
    "\n",
    "# Generate outputs passed on the tokenized input\n",
    "# See generate docs: https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/text_generation#transformers.GenerationConfig \n",
    "outputs = llm_model.generate(**input_ids, \n",
    "                             temperature=0.7, \n",
    "                             do_sample=True, \n",
    "                             top_p=0.95, \n",
    "                             top_k=40, \n",
    "                             max_new_tokens=512) # define the maximum number of new tokens to create\n",
    "# outputs = llm_model.generate(**input_ids,\n",
    "#                              max_new_tokens=256) # define the maximum number of new tokens to create\n",
    "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (decoded):\n",
      "<s><|im_start|> system\n",
      "You are a robotic operating system (ROS) developer<|im_end|> \n",
      "<|im_start|> user\n",
      "What is ros?<|im_end|> \n",
      "<|im_start|> assistant\n",
      "ROS, or Robot Operating System, is an open-source, meta-operating system primarily designed for the development and maintenance of robotics applications. It provides a flexible, modular framework to develop, integrate, and maintain various components of a robot's software stack, such as perception, localization, motion planning, and decision-making.\n",
      "\n",
      "ROS consists of a set of tools, libraries, and conventions that facilitate the creation of complex, modular robotics software systems. It allows developers to easily reuse code, integrate new algorithms, and collaborate on robotics projects.\n",
      "\n",
      "Key features of ROS include a message-passing system for inter-process communication, a package management system, a set of tools for building and running robot applications, and a large collection of pre-built packages for various robotics tasks.\n",
      "\n",
      "In summary, ROS is a powerful, flexible, and open-source tool that simplifies the development and maintenance of robotics software applications, enabling researchers, engineers, and enthusiasts to focus on their core problems and collaborate more efficiently.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode the output tokens to text\n",
    "outputs_decoded = tokenizer.decode(outputs[0])\n",
    "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s><|im_start|> system\\nYou are a robotic operating system (ROS) developer<|im_end|> \\n<|im_start|> user\\nWhat is ros?<|im_end|> \\n<|im_start|> assistant\\nROS, or Robot Operating System, is an open-source, meta-operating system primarily designed for the development and maintenance of robotics applications. It provides a flexible, modular framework to develop, integrate, and maintain various components of a robot's software stack, such as perception, localization, motion planning, and decision-making.\\n\\nROS consists of a set of tools, libraries, and conventions that facilitate the creation of complex, modular robotics software systems. It allows developers to easily reuse code, integrate new algorithms, and collaborate on robotics projects.\\n\\nKey features of ROS include a message-passing system for inter-process communication, a package management system, a set of tools for building and running robot applications, and a large collection of pre-built packages for various robotics tasks.\\n\\nIn summary, ROS is a powerful, flexible, and open-source tool that simplifies the development and maintenance of robotics software applications, enabling researchers, engineers, and enthusiasts to focus on their core problems and collaborate more efficiently.<|im_end|>\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = prompt.replace('<|im_start|>', '<|im_start|> ').replace('<|im_end|>\\n', '<|im_end|> \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|> system\\nYou are a robotic operating system (ROS) developer<|im_end|> \\n<|im_start|> user\\nWhat is ros?<|im_end|> \\n<|im_start|> assistant\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)):\n",
    "    if not a[i] == outputs_decoded[3 + i]:\n",
    "        print(i, a[i], outputs_decoded[3 + i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>ROS, or Robot Operating System, is an open-source, meta-operating system primarily designed for the development and maintenance of robotics applications. It provides a flexible, modular framework to develop, integrate, and maintain various components of a robot's software stack, such as perception, localization, motion planning, and decision-making.\\n\\nROS consists of a set of tools, libraries, and conventions that facilitate the creation of complex, modular robotics software systems. It allows developers to easily reuse code, integrate new algorithms, and collaborate on robotics projects.\\n\\nKey features of ROS include a message-passing system for inter-process communication, a package management system, a set of tools for building and running robot applications, and a large collection of pre-built packages for various robotics tasks.\\n\\nIn summary, ROS is a powerful, flexible, and open-source tool that simplifies the development and maintenance of robotics software applications, enabling researchers, engineers, and enthusiasts to focus on their core problems and collaborate more efficiently.<|im_end|>\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_decoded.replace(a, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (decoded):\n",
      "ROS, or Robot Operating System, is an open-source, meta-operating system primarily designed for the development and maintenance of robotics applications. It provides a flexible, modular framework to develop, integrate, and maintain various components of a robot's software stack, such as perception, localization, motion planning, and decision-making.\n",
      "\n",
      "ROS consists of a set of tools, libraries, and conventions that facilitate the creation of complex, modular robotics software systems. It allows developers to easily reuse code, integrate new algorithms, and collaborate on robotics projects.\n",
      "\n",
      "Key features of ROS include a message-passing system for inter-process communication, a package management system, a set of tools for building and running robot applications, and a large collection of pre-built packages for various robotics tasks.\n",
      "\n",
      "In summary, ROS is a powerful, flexible, and open-source tool that simplifies the development and maintenance of robotics software applications, enabling researchers, engineers, and enthusiasts to focus on their core problems and collaborate more efficiently.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(prompt)\n",
    "print(f\"Model output (decoded):\\n{outputs_decoded.replace('<s>', '').replace(a, '').replace('<|im_end|>', '')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: What is ros?\n",
      "\n",
      "Output text:\n",
      "ROS, or Robot Operating System, is an open-source, meta-operating system primarily designed for the development and maintenance of robotics applications. It provides a flexible, modular framework to develop, integrate, and maintain various components of a robot's software stack, such as perception, localization, motion planning, and decision-making.\n",
      "\n",
      "ROS consists of a set of tools, libraries, and conventions that facilitate the creation of complex, modular robotics software systems. It allows developers to easily reuse code, integrate new algorithms, and collaborate on robotics projects.\n",
      "\n",
      "Key features of ROS include a message-passing system for inter-process communication, a package management system, a set of tools for building and running robot applications, and a large collection of pre-built packages for various robotics tasks.\n",
      "\n",
      "In summary, ROS is a powerful, flexible, and open-source tool that simplifies the development and maintenance of robotics software applications, enabling researchers, engineers, and enthusiasts to focus on their core problems and collaborate more efficiently.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input text: {input_text}\\n\")\n",
    "print(f\"Output text:\\n{outputs_decoded.replace('<s>', '').replace(a, '').replace('<|im_end|>', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nutrition-style questions generated with GPT4\n",
    "gpt4_questions = [\n",
    "    \"WWhat are the main differences between ROS 1 and ROS 2?\",\n",
    "    \"Explain the concept of topics, services, and actions in ROS.\",\n",
    "    \"What is the purpose of the catkin_make command in ROS 1?\",\n",
    "    \"What is the function of rviz in ROS?\",\n",
    "    \"What is the purpose of rqt_graph, and how can it help in debugging a ROS system?\"\n",
    "] \n",
    "\n",
    "# Manually created question list\n",
    "manual_questions = [\n",
    "    \"What is ros?\",\n",
    "]\n",
    "\n",
    "query_list = gpt4_questions + manual_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the function of rviz in ROS?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "query = random.choice(query_list)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = qdrant.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=model.encode(query),\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and great libraries that's not all. ros is said to be language agnostic. it means that you can program some parts. of your application. in a programming language and another. part\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result[0].payload['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Similarity Search and LLM output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(query: str, \n",
    "                     context_items: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Augments query with text-based context from context_items.\n",
    "    \"\"\"\n",
    "    # Join context items into one dotted paragraph\n",
    "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
    "\n",
    "    # # Create a base prompt with examples to help the model\n",
    "    # # Note: this is very customizable, I've chosen to use 3 examples of the answer style we'd like.\n",
    "    # # We could also write this in a txt file and import it in if we wanted.\n",
    "    # base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
    "    # Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
    "    # Don't return the thinking, only return the answer.\n",
    "    # Make sure your answers are as explanatory as possible.\n",
    "    # Use the following examples as reference for the ideal answer style.\n",
    "    # \\nExample 1:\n",
    "    # Query: What are the fat-soluble vitamins?\n",
    "    # Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
    "    # \\nExample 2:\n",
    "    # Query: What are the causes of type 2 diabetes?\n",
    "    # Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
    "    # \\nExample 3:\n",
    "    # Query: What is the importance of hydration for physical performance?\n",
    "    # Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
    "    # \\nNow use the following context items to answer the user query:\n",
    "    # {context}\n",
    "    # \\nRelevant passages: <extract relevant passages from the context here>\n",
    "    # User query: {query}\n",
    "    # Answer:\"\"\"\n",
    "\n",
    "    # # Update base prompt with context items and query   \n",
    "    # base_prompt = base_prompt.format(context=context, query=query)\n",
    "\n",
    "    # # Create prompt template for instruction-tuned model\n",
    "    # dialogue_template = [\n",
    "    #     {\"role\": \"user\",\n",
    "    #     \"content\": base_prompt}\n",
    "    # ]\n",
    "\n",
    "    # # Apply the chat template\n",
    "    # prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "    #                                       tokenize=False,\n",
    "    #                                       add_generation_prompt=True)\n",
    "    # return prompt\n",
    "\n",
    "    system_message = f\"You are a robotic operating system (ROS) developer, using given context as additional information and answer the query, just your answer explanatory answer would suffice. Here is the context:{context}.\" # For out task we can use this as a system message\n",
    "\n",
    "    prompt=f'''<|im_start|>system\n",
    "    {system_message}<|im_end|>\n",
    "    <|im_start|>user\n",
    "    {query}<|im_end|>\n",
    "    <|im_start|>assistant\n",
    "    '''\n",
    "    return prompt\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the function of rviz in ROS?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\n    You are a robotic operating system (ROS) developer, using given context as additional information and answer the query, just your answer explanatory answer would suffice. Here is the context:- and great libraries that's not all. ros is said to be language agnostic. it means that you can program some parts. of your application. in a programming language and another. part\\n- powered by ros. using python and c plus plus. ros is also open source with an. active and growing community so. you can directly see what's going on you. can get help\\n- and a framework built especially for. robotics applications rao's goal. is to provide a standard for robotic. software. that developers can use and reuse in. any robot once you know how to use ros\\n- so this is the why behind ross. now when to use ros maybe. you've already started to program robots. with. an arduino board with a custom code. on a computer and what you will quickly\\n- all the external libraries that exist. for many different robots. we will mostly focus on the ros basics. and core functionalities that will. enable you. to easily start any robot application.<|im_end|>\\n    <|im_start|>user\\n    What is the function of rviz in ROS?<|im_end|>\\n    <|im_start|>assistant\\n    \""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import random\n",
    "query = random.choice(query_list)\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Get relevant resources\n",
    "# scores, indices = retrieve_relevant_resources(query=query,\n",
    "#                                               embeddings=embeddings)\n",
    "search_results = qdrant.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=model.encode(query),\n",
    "    limit=5\n",
    ")\n",
    "    \n",
    "# Create a list of context items\n",
    "# context_items = [pages_and_chunks[i] for i in indices]\n",
    "context_items = []\n",
    "for result in search_results:\n",
    "    context_items.append({\"sentence_chunk\": result.payload['text']})\n",
    "\n",
    "# Format prompt with context items\n",
    "prompt = prompt_formatter(query=query,\n",
    "                          context_items=context_items)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the function of rviz in ROS?\n",
      "RAG answer:\n",
      "\n",
      "    Rviz, in ROS (Robotic Operating System), is a 3D visualization tool that serves as a visualization and interaction environment for ROS data. It allows users to visualize and interact with data from robots or simulations in a 3D environment.\n",
      "\n",
      "    The primary functions of Rviz include:\n",
      "\n",
      "    1. Visualization: Rviz can display various types of data, such as sensor data (e.g., from lidar or cameras), robot models, and path planning visualizations. This visualization helps users understand the robot's state and plan actions accordingly.\n",
      "    2. Interaction: Rviz allows users to interact with the robot's environment by manipulating objects, setting waypoints, and controlling robot movement.\n",
      "    3. Configuration: Rviz enables users to configure visualization settings, such as changing colors or styles, to better suit their needs or preferences.\n",
      "    4. Plugin system: Rviz supports plugins, which are reusable components that provide specific functionalities. Users can create their own plugins or use existing ones to add advanced features to their visualization environment.\n",
      "    5. Roscontrol integration: Rviz can interact with roscontrol, a ROS package that helps manage hardware and software components of a robot. This integration allows users to control the robot's power, enable and disable actuators, and perform other actions through Rviz.\n",
      "\n",
      "    In summary, Rviz provides a 3D visualization and interaction environment for ROS data, enabling users to effectively plan and control robot actions while also configuring visualization settings and utilizing plugins for advanced features.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate an output of tokens\n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             temperature=0.7, # lower temperature = more deterministic outputs, higher temperature = more creative outputs\n",
    "                             do_sample=True, # whether or not to use sampling, see https://huyenchip.com/2024/01/16/sampling.html for more\n",
    "                             top_p=0.95, \n",
    "                             top_k=40, \n",
    "                             max_new_tokens=512) # how many new tokens to generate from prompt \n",
    "\n",
    "# Turn the output tokens into text\n",
    "output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "a = prompt.replace('<|im_start|>', '<|im_start|> ').replace('<|im_end|>\\n', '<|im_end|> \\n')\n",
    "print(f\"RAG answer:\\n{output_text.replace('<s>', '').replace(a, '').replace('<|im_end|>', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query, \n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_new_tokens=512,\n",
    "        format_answer_text=True, \n",
    "        return_answer_only=True):\n",
    "    \"\"\"\n",
    "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get just the scores and indices of top related results\n",
    "    # scores, indices = retrieve_relevant_resources(query=query,\n",
    "    #                                               embeddings=embeddings)\n",
    "    search_results = qdrant.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=model.encode(query),\n",
    "    limit=5\n",
    ")\n",
    "    \n",
    "    # Create a list of context items\n",
    "    # context_items = [pages_and_chunks[i] for i in indices]\n",
    "    context_items = []\n",
    "    for result in search_results:\n",
    "        context_items.append({\"sentence_chunk\": result.payload['text']})\n",
    "\n",
    "    scores = [result.score for result in search_results]\n",
    "\n",
    "    # Add score to context item\n",
    "    for i, item in enumerate(context_items):\n",
    "        item[\"score\"] = scores[i] # return score back to CPU \n",
    "        \n",
    "    # Format the prompt with context items\n",
    "    prompt = prompt_formatter(query=query,\n",
    "                              context_items=context_items)\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate an output of tokens\n",
    "    outputs = llm_model.generate(**input_ids,\n",
    "                                 temperature=temperature,\n",
    "                                 do_sample=True,\n",
    "                                 top_p=top_p,\n",
    "                                 top_k=top_k,\n",
    "                                 max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # Turn the output tokens into text\n",
    "    output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "    if format_answer_text:\n",
    "        # Replace special tokens and unnecessary help message\n",
    "        prompt_format_matched = prompt.replace('<|im_start|>', '<|im_start|> ').replace('<|im_end|>\\n', '<|im_end|> \\n')\n",
    "        output_text = output_text.replace('<s>', '').replace(prompt_format_matched, '').replace('<|im_end|>', '')\n",
    "\n",
    "    # Only return the answer without the context items\n",
    "    if return_answer_only:\n",
    "        return output_text, \"No context items returned\"\n",
    "    \n",
    "    return output_text, context_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to print wrapped text \n",
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: WWhat are the main differences between ROS 1 and ROS 2?\n"
     ]
    }
   ],
   "source": [
    "query = random.choice(query_list)\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Answer query with context and return context \n",
    "answer, context_items = ask(query=query, \n",
    "                            temperature=0.7,\n",
    "                            max_new_tokens=512,\n",
    "                            return_answer_only=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\n",
      "     ROS 1 and ROS 2 are two major versions of the Robot Operating System (ROS).\n",
      "They share some similarities but have key differences. Here are the main\n",
      "differences between ROS 1 and ROS 2:      1. Language Support: ROS 1 primarily\n",
      "uses Python for communication between nodes, while ROS 2 supports multiple\n",
      "languages, including C++, Python, and others, making it more language-agnostic.\n",
      "2. Data Transport: ROS 1 uses a custom data transport protocol called TCPROS,\n",
      "while ROS 2 uses the Data Distribution Service (DDS) as its data transport\n",
      "mechanism. DDS is more reliable, scalable, and real-time capable.     3.\n",
      "Architecture: ROS 2 has a modular architecture with a smaller core set of\n",
      "components, making it easier to maintain and extend. ROS 1 has a larger core set\n",
      "of components.     4. Lifecycle Nodes: ROS 2 introduces a node lifecycle model,\n",
      "allowing nodes to transition between states (e.g., idle, pre-operational,\n",
      "operational, and post-operational) and handle events, making the system more\n",
      "robust and flexible.     5. Hardware Abstraction: ROS 2 includes a hardware\n",
      "abstraction layer (HAL) that simplifies hardware interactions across different\n",
      "platforms.     6. Built-in ROS Packages: ROS 2 has a smaller set of built-in\n",
      "packages compared to ROS 1, making it easier to manage and extend the system.\n",
      "7. Dependency Management: ROS 2 uses Ament (Assemble, Modular, Execution, Not\n",
      "Entangled) for dependency management, which is more modern and flexible compared\n",
      "to catkin in ROS 1.     8. Compatibility: ROS 1 and ROS 2 are not directly\n",
      "compatible, meaning that code and packages developed for one version may not\n",
      "work directly with the other. However, some packages and libraries can be shared\n",
      "between both versions using tools like ros2rclpy_wrapper.     9. Community and\n",
      "Support: ROS 1 has a larger community and more existing resources, while ROS 2\n",
      "is still growing and gaining traction.     10. Long-term Support: ROS 2 aims to\n",
      "provide long-term support for its releases, ensuring stability and reliability\n",
      "over time\n",
      "Context items:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sentence_chunk': \"and great libraries that's not all. ros is said to be language agnostic. it means that you can program some parts. of your application. in a programming language and another. part\",\n",
       "  'score': 0.5012295246124268},\n",
       " {'sentence_chunk': \"powered by ros. using python and c plus plus. ros is also open source with an. active and growing community so. you can directly see what's going on you. can get help\",\n",
       "  'score': 0.41342034935951233},\n",
       " {'sentence_chunk': \"so this is the why behind ross. now when to use ros maybe. you've already started to program robots. with. an arduino board with a custom code. on a computer and what you will quickly\",\n",
       "  'score': 0.4084434509277344},\n",
       " {'sentence_chunk': \"and a framework built especially for. robotics applications rao's goal. is to provide a standard for robotic. software. that developers can use and reuse in. any robot once you know how to use ros\",\n",
       "  'score': 0.28597965836524963},\n",
       " {'sentence_chunk': 'joystick and so on. and each of those independent blocks. will communicate. between each other in a way that. is powerful and scalable. the second main point is that ross',\n",
       "  'score': 0.2675519585609436}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Answer:\\n\")\n",
    "print_wrapped(answer)\n",
    "print(f\"Context items:\")\n",
    "context_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the common point between all\n",
      "those robots\n",
      "well all the robots you see here are\n",
      "or can be powered by rouse\n",
      "roth means robot operating system\n",
      "it is something between a middleware\n",
      "and a framework built especially for\n",
      "robotics applications rao's goal\n",
      "is to provide a standard for robotic\n",
      "software\n",
      "that developers can use and reuse in\n",
      "any robot once you know how to use ros\n",
      "efficiently you will be able to set up\n",
      "a new software for a new robot in no\n",
      "time\n",
      "you first need to master the basics and\n",
      "core functionalities\n",
      "which you will see in this course and\n",
      "then\n",
      "for every new robot you program you will\n",
      "gain more skills\n",
      "that can apply to other robots\n",
      "the more you know about ross the easiest\n",
      "it will be for you to program and\n",
      "understand\n",
      "the code of any robot\n",
      "but is that it no another\n",
      "philosophy behind ross is don't reinvent\n",
      "the wheel reinventing the wheel is a\n",
      "very common problem\n",
      "in robotics people always start building\n",
      "new software\n",
      "that is already existing and thus they\n",
      "don't have the time\n",
      "to work on really valuable stuff\n",
      "what if instead you could build on a\n",
      "strong\n",
      "software base to directly program\n",
      "high-level functionalities\n",
      "and work on use cases instead of\n",
      "low-level technical stuff that already\n",
      "exists in way\n",
      "so this is the why behind ross\n",
      "now when to use ros maybe\n",
      "you've already started to program robots\n",
      "with\n",
      "an arduino board with a custom code\n",
      "on a computer and what you will quickly\n",
      "experience\n",
      "is that the more sensors actuators\n",
      "controllers you add on your application\n",
      "the more complex\n",
      "it becomes until you reach a point\n",
      "where everything is mixed up and\n",
      "you can't add any code for a new sensor\n",
      "without having a huge headache\n",
      "ross is here to help you develop\n",
      "powerful\n",
      "and scalable robotic applications\n",
      "you can use it whenever you want to\n",
      "create a robot software\n",
      "which needs a lot of communication\n",
      "between its\n",
      "sub-programs or has some functionalities\n",
      "that go beyond a very simple use case\n",
      "etc so for a robot\n",
      "that will just open a door with a servo\n",
      "motor when it detects a movement\n",
      "maybe you don't need routes but for a\n",
      "mobile robot\n",
      "which you want to control with a gps and\n",
      "a camera\n",
      "in this case ross might really help you\n",
      "alright you've just seen what is the why\n",
      "behind ross\n",
      "and when to use it now what is ross\n",
      "it would be hard to describe exactly\n",
      "what is ross in about two minutes\n",
      "even an hour but here are two main\n",
      "points\n",
      "that will give you an idea of the big\n",
      "picture\n",
      "first of all ross provides you with a\n",
      "way of\n",
      "separating your code into reusable\n",
      "blocks\n",
      "along with a set of communication tools\n",
      "to easily communicate between all your\n",
      "sub-programs\n",
      "let's say that you are programming a\n",
      "robotic arm\n",
      "you can create a subprogram called\n",
      "node for your camera another for the\n",
      "motion planning\n",
      "another one for the hardware driver\n",
      "another for\n",
      "joystick and so on\n",
      "and each of those independent blocks\n",
      "will communicate\n",
      "between each other in a way that\n",
      "is powerful and scalable\n",
      "the second main point is that ross\n",
      "provides you with many plug-and-play\n",
      "libraries\n",
      "that will save you a huge amount of time\n",
      "and most importantly that will prevent\n",
      "you\n",
      "from reinventing the wheel if we come\n",
      "back to the robotic arm\n",
      "imagine how difficult it can be to\n",
      "compute\n",
      "the inverse kinematic for the arm to\n",
      "plan a trajectory\n",
      "which will make the arm move smoothly\n",
      "and\n",
      "avoid any obstacle on the way\n",
      "impossible you might think unless you\n",
      "spend\n",
      "two years studying mathematics motion\n",
      "planning\n",
      "etc but what if i tell you this\n",
      "you don't need two years you need maybe\n",
      "two days\n",
      "to install a library and figure out\n",
      "how to use it so you have great\n",
      "communication tools\n",
      "and great libraries that's not all\n",
      "ros is said to be language agnostic\n",
      "it means that you can program some parts\n",
      "of your application\n",
      "in a programming language and another\n",
      "part\n",
      "in another programming language simply\n",
      "because\n",
      "the communication tools don't rely on a\n",
      "specific\n",
      "language so in this course we will not\n",
      "go into\n",
      "all the external libraries that exist\n",
      "for many different robots\n",
      "we will mostly focus on the ros basics\n",
      "and core functionalities that will\n",
      "enable you\n",
      "to easily start any robot application\n",
      "powered by ros\n",
      "using python and c plus plus\n",
      "ros is also open source with an\n",
      "active and growing community so\n",
      "you can directly see what's going on you\n",
      "can get help\n",
      "share your project and even contribute\n",
      "if you wish to all right with this quick\n",
      "introduction\n",
      "you should get some ideas about what is\n",
      "wrong\n",
      "when to use it and why it is useful\n",
      "don't panic though if you don't\n",
      "understand everything right now\n",
      "the big picture behind ross is pretty\n",
      "hard to get\n",
      "at the beginning but after some practice\n",
      "you will start to get it and i can\n",
      "guarantee you\n",
      "that you will quickly think that ross\n",
      "is awesome\n"
     ]
    }
   ],
   "source": [
    "def get_youtube_transcript(video_url: str) -> list:\n",
    "    video_id = video_url.split(\"v=\")[1]\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    return transcript\n",
    "video_url = \"https://www.youtube.com/watch?v=8QfI5a7lTKU\"\n",
    "video_id = video_url.split(\"v=\")[1]\n",
    "\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "for segment in transcript:\n",
    "    print(segment['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript stored into MongoDB\n"
     ]
    }
   ],
   "source": [
    "## MongoDB\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")  # Replace with your MongoDB connection string\n",
    "db = client[\"youtube_database\"]  # Database name\n",
    "collection = db[\"transcripts\"]   # Collection name\n",
    "\n",
    "# Insert into MongoDB\n",
    "document = {\n",
    "    \"source\": \"youtube\",\n",
    "    \"video_id\": video_id,\n",
    "    \"transcript\": transcript\n",
    "}\n",
    "\n",
    "collection.insert_one(document)\n",
    "print(\"Transcript stored into MongoDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_id', 'video_id', 'transcript'])\n"
     ]
    }
   ],
   "source": [
    "result = collection.find_one({\"video_id\": video_id})\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what is the common point between all', 'those robots', 'well all the robots you see here are', 'or can be powered by rouse', 'roth means robot operating system', 'it is something between a middleware', 'and a framework built especially for', \"robotics applications rao's goal\", 'is to provide a standard for robotic', 'software', 'that developers can use and reuse in', 'any robot once you know how to use ros', 'efficiently you will be able to set up', 'a new software for a new robot in no', 'time', 'you first need to master the basics and', 'core functionalities', 'which you will see in this course and', 'then', 'for every new robot you program you will', 'gain more skills', 'that can apply to other robots', 'the more you know about ross the easiest', 'it will be for you to program and', 'understand', 'the code of any robot', 'but is that it no another', \"philosophy behind ross is don't reinvent\", 'the wheel reinventing the wheel is a', 'very common problem', 'in robotics people always start building', 'new software', 'that is already existing and thus they', \"don't have the time\", 'to work on really valuable stuff', 'what if instead you could build on a', 'strong', 'software base to directly program', 'high-level functionalities', 'and work on use cases instead of', 'low-level technical stuff that already', 'exists in way', 'so this is the why behind ross', 'now when to use ros maybe', \"you've already started to program robots\", 'with', 'an arduino board with a custom code', 'on a computer and what you will quickly', 'experience', 'is that the more sensors actuators', 'controllers you add on your application', 'the more complex', 'it becomes until you reach a point', 'where everything is mixed up and', \"you can't add any code for a new sensor\", 'without having a huge headache', 'ross is here to help you develop', 'powerful', 'and scalable robotic applications', 'you can use it whenever you want to', 'create a robot software', 'which needs a lot of communication', 'between its', 'sub-programs or has some functionalities', 'that go beyond a very simple use case', 'etc so for a robot', 'that will just open a door with a servo', 'motor when it detects a movement', \"maybe you don't need routes but for a\", 'mobile robot', 'which you want to control with a gps and', 'a camera', 'in this case ross might really help you', \"alright you've just seen what is the why\", 'behind ross', 'and when to use it now what is ross', 'it would be hard to describe exactly', 'what is ross in about two minutes', 'even an hour but here are two main', 'points', 'that will give you an idea of the big', 'picture', 'first of all ross provides you with a', 'way of', 'separating your code into reusable', 'blocks', 'along with a set of communication tools', 'to easily communicate between all your', 'sub-programs', \"let's say that you are programming a\", 'robotic arm', 'you can create a subprogram called', 'node for your camera another for the', 'motion planning', 'another one for the hardware driver', 'another for', 'joystick and so on', 'and each of those independent blocks', 'will communicate', 'between each other in a way that', 'is powerful and scalable', 'the second main point is that ross', 'provides you with many plug-and-play', 'libraries', 'that will save you a huge amount of time', 'and most importantly that will prevent', 'you', 'from reinventing the wheel if we come', 'back to the robotic arm', 'imagine how difficult it can be to', 'compute', 'the inverse kinematic for the arm to', 'plan a trajectory', 'which will make the arm move smoothly', 'and', 'avoid any obstacle on the way', 'impossible you might think unless you', 'spend', 'two years studying mathematics motion', 'planning', 'etc but what if i tell you this', \"you don't need two years you need maybe\", 'two days', 'to install a library and figure out', 'how to use it so you have great', 'communication tools', \"and great libraries that's not all\", 'ros is said to be language agnostic', 'it means that you can program some parts', 'of your application', 'in a programming language and another', 'part', 'in another programming language simply', 'because', \"the communication tools don't rely on a\", 'specific', 'language so in this course we will not', 'go into', 'all the external libraries that exist', 'for many different robots', 'we will mostly focus on the ros basics', 'and core functionalities that will', 'enable you', 'to easily start any robot application', 'powered by ros', 'using python and c plus plus', 'ros is also open source with an', 'active and growing community so', \"you can directly see what's going on you\", 'can get help', 'share your project and even contribute', 'if you wish to all right with this quick', 'introduction', 'you should get some ideas about what is', 'wrong', 'when to use it and why it is useful', \"don't panic though if you don't\", 'understand everything right now', 'the big picture behind ross is pretty', 'hard to get', 'at the beginning but after some practice', 'you will start to get it and i can', 'guarantee you', 'that you will quickly think that ross', 'is awesome']\n"
     ]
    }
   ],
   "source": [
    "# Extract text from transcripts\n",
    "sentences = [i['text'] for i in result['transcript']]\n",
    "print(sentences)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# Chunk sentences together for embedding\n",
    "#TODO: Make this chunking better:Maybe capitalize and fins end of sentences in a better way\n",
    "sentences_in_chunk = 6\n",
    "chunks = []\n",
    "for i in range(0, len(sentences), sentences_in_chunk):\n",
    "    chunks.append(\". \".join(sentences[i:i + sentences_in_chunk]))\n",
    "\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 384)\n"
     ]
    }
   ],
   "source": [
    "# Embed these chunks\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2') # TODO: Pick better models\n",
    "\n",
    "embeddings = model.encode(chunks)\n",
    "embeddings_dict = dict(zip(chunks, embeddings))\n",
    "print(embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings stored into MongoDB\n"
     ]
    }
   ],
   "source": [
    "# Store embeddings in MongoDB\n",
    "# Insert into MongoDB\n",
    "collection = db[\"embeddings\"]   # Collection name\n",
    "document = {\n",
    "    \"source\": \"youtube\",\n",
    "    \"video_id\": video_id,\n",
    "    \"embeddings\": embeddings.tolist()\n",
    "}\n",
    "\n",
    "collection.insert_one(document)\n",
    "print(\"Embeddings stored into MongoDB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Do further preprocessing to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Similarity search using qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from torchvision.transforms import Resize\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "qdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance, for testing, CI/CD\n",
    "\n",
    "#Create a collection or database of texts where you store the embeddings\n",
    "my_collection = \"text_collection\"\n",
    "\n",
    "qdrant.create_collection(\n",
    "    collection_name=my_collection,\n",
    "    vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE)\n",
    ")\n",
    "\n",
    "# Insert embeddings into Qdrant\n",
    "for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "    qdrant.upsert(\n",
    "        collection_name=my_collection,\n",
    "        points=[models.PointStruct(\n",
    "            id=i,\n",
    "            vector=embedding,\n",
    "            payload={\"text\": chunk}\n",
    "        )]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant.count(\n",
    "    collection_name=my_collection,\n",
    "    exact=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity test\n",
    "sample_sentence = \"What is the meaning of life?\"\n",
    "sample_embedding = model.encode(sample_sentence)\n",
    "search_result = qdrant.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=sample_embedding,\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=21, version=0, score=0.15166017413139343, payload={'text': \"and great libraries that's not all. ros is said to be language agnostic. it means that you can program some parts. of your application. in a programming language and another. part\"}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=10, version=0, score=0.07326250523328781, payload={'text': 'create a robot software. which needs a lot of communication. between its. sub-programs or has some functionalities. that go beyond a very simple use case. etc so for a robot'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=0, version=0, score=0.061092559248209, payload={'text': 'what is the common point between all. those robots. well all the robots you see here are. or can be powered by rouse. roth means robot operating system. it is something between a middleware'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=22, version=0, score=0.05160965770483017, payload={'text': \"in another programming language simply. because. the communication tools don't rely on a. specific. language so in this course we will not. go into\"}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=4, version=0, score=0.05022667348384857, payload={'text': \"understand. the code of any robot. but is that it no another. philosophy behind ross is don't reinvent. the wheel reinventing the wheel is a. very common problem\"}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 4 GB\n"
     ]
    }
   ],
   "source": [
    "# Get GPU available memory\n",
    "import torch\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
    "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e16cf8186db4720a23c5cee11d1817f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_quantization_config = False\n",
    "model_id = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using attention implementation: sdpa\n",
      "[INFO] Using model_id: gpt2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils import is_flash_attn_2_available \n",
    "\n",
    "# 1. Create quantization config for smaller model loading (optional)\n",
    "# Requires !pip install bitsandbytes accelerate, see: https://github.com/TimDettmers/bitsandbytes, https://huggingface.co/docs/accelerate/\n",
    "# For models that require 4-bit quantization (use this if you have low GPU memory available)\n",
    "from transformers import BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "# Bonus: Setup Flash Attention 2 for faster inference, default to \"sdpa\" or \"scaled dot product attention\" if it's not available\n",
    "# Flash Attention 2 requires NVIDIA GPU compute capability of 8.0 or above, see: https://developer.nvidia.com/cuda-gpus\n",
    "# Requires !pip install flash-attn, see: https://github.com/Dao-AILab/flash-attention \n",
    "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
    "  attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "  attn_implementation = \"sdpa\"\n",
    "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
    "\n",
    "# 2. Pick a model we'd like to use (this will depend on how much GPU memory you have available)\n",
    "# model_id = \"google/gemma-7b-it\"\n",
    "model_id = model_id # (we already set this above)\n",
    "print(f\"[INFO] Using model_id: {model_id}\")\n",
    "\n",
    "# 3. Instantiate tokenizer (tokenizer turns text into numbers ready for the model) \n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id)\n",
    "\n",
    "# 4. Instantiate the model\n",
    "# llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id, \n",
    "#                                                  torch_dtype=torch.float16, # datatype to use, we want float16\n",
    "#                                                  quantization_config=quantization_config if use_quantization_config else None,\n",
    "#                                                  low_cpu_mem_usage=False, # use full memory \n",
    "#                                                  attn_implementation=attn_implementation) # which attention version to use\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id)\n",
    "\n",
    "if not use_quantization_config: # quantization takes care of device setting automatically, so if it's not used, send model to GPU \n",
    "    llm_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model.eval() # put model in evaluation mode\n",
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124439808"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_num_params(model: torch.nn.Module):\n",
    "    return sum([param.numel() for param in model.parameters()])\n",
    "\n",
    "get_model_num_params(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_mem_bytes': 510342192, 'model_mem_mb': 486.7, 'model_mem_gb': 0.48}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_mem_size(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Get how much memory a PyTorch model takes up.\n",
    "\n",
    "    See: https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822\n",
    "    \"\"\"\n",
    "    # Get model parameters and buffer sizes\n",
    "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
    "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
    "\n",
    "    # Calculate various model sizes\n",
    "    model_mem_bytes = mem_params + mem_buffers # in bytes\n",
    "    model_mem_mb = model_mem_bytes / (1024**2) # in megabytes\n",
    "    model_mem_gb = model_mem_bytes / (1024**3) # in gigabytes\n",
    "\n",
    "    return {\"model_mem_bytes\": model_mem_bytes,\n",
    "            \"model_mem_mb\": round(model_mem_mb, 2),\n",
    "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
    "\n",
    "get_model_mem_size(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "What is ros?\n",
      "Input IDs:\n",
      "tensor([[2061,  318,  686,   82,   30]])\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What is ros?\"\n",
    "print(f\"Input text:\\n{input_text}\")\n",
    "\n",
    "# Tokenize the input text\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "print(f\"Input IDs:\\n{input_ids}\")\n",
    "\n",
    "prompt = input_text #TODO: Fix a prompt structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input (tokenized):\n",
      "{'input_ids': tensor([[2061,  318,  686,   82,   30]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "\n",
      "Model output (tokens):\n",
      "tensor([ 2061,   318,   686,    82,    30,   198,   198,    49,  4629,   389,\n",
      "          257,  2099,   286, 17182,   973,   284,  1745,   257, 17182,    13,\n",
      "         1119,   389,   973,   284,  1745,   257, 17182,   287,  1295,    11,\n",
      "          393,   284,  1745,   257, 17182,   287,  1295,   319,   257,  3704,\n",
      "          286,  4898,    13,  1119,   389,   635,   973,   284,  1745,   257,\n",
      "        17182,   287,  1295,   319,   257,  3704,   286,  4898,    13,   198,\n",
      "          198,    49,  4629,   389,   973,   284,  1745,   257, 17182,   287,\n",
      "         1295,   319,   257,  3704,   286,  4898,    13,  1119,   389,   635,\n",
      "          973,   284,  1745,   257, 17182,   287,  1295,   319,   257,  3704,\n",
      "          286,  4898,    13,   198,   198,    49,  4629,   389,   973,   284,\n",
      "         1745,   257, 17182,   287,  1295,   319,   257,  3704,   286,  4898,\n",
      "           13,  1119,   389,   635,   973,   284,  1745,   257, 17182,   287,\n",
      "         1295,   319,   257,  3704,   286,  4898,    13,   198,   198,    49,\n",
      "         4629,   389,   973,   284,  1745,   257, 17182,   287,  1295,   319,\n",
      "          257,  3704,   286,  4898,    13,  1119,   389,   635,   973,   284,\n",
      "         1745,   257, 17182,   287,  1295,   319,   257,  3704,   286,  4898,\n",
      "           13,   198,   198,    49,  4629,   389,   973,   284,  1745,   257,\n",
      "        17182,   287,  1295,   319,   257,  3704,   286,  4898,    13,  1119,\n",
      "          389,   635,   973,   284,  1745,   257, 17182,   287,  1295,   319,\n",
      "          257,  3704,   286,  4898,    13,   198,   198,    49,  4629,   389,\n",
      "          973,   284,  1745,   257, 17182,   287,  1295,   319,   257,  3704,\n",
      "          286,  4898,    13,  1119,   389,   635,   973,   284,  1745,   257,\n",
      "        17182,   287,  1295,   319,   257,  3704,   286,  4898,    13,   198,\n",
      "          198,    49,  4629,   389,   973,   284,  1745,   257, 17182,   287,\n",
      "         1295,   319,   257,  3704,   286,  4898,    13,  1119,   389,   635,\n",
      "          973,   284,  1745,   257, 17182,   287,  1295,   319,   257,  3704,\n",
      "          286], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text (turn it into numbers) and send it to GPU\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
    "\n",
    "# Generate outputs passed on the tokenized input\n",
    "# See generate docs: https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/text_generation#transformers.GenerationConfig \n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             max_new_tokens=256) # define the maximum number of new tokens to create\n",
    "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (decoded):\n",
      "What is ros?\n",
      "\n",
      "Roses are a type of rope used to hold a rope. They are used to hold a rope in place, or to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of wood.\n",
      "\n",
      "Roses are used to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of wood.\n",
      "\n",
      "Roses are used to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of wood.\n",
      "\n",
      "Roses are used to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of wood.\n",
      "\n",
      "Roses are used to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of wood.\n",
      "\n",
      "Roses are used to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of wood.\n",
      "\n",
      "Roses are used to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode the output tokens to text\n",
    "outputs_decoded = tokenizer.decode(outputs[0])\n",
    "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: What is ros?\n",
      "\n",
      "Output text:\n",
      "\n",
      "\n",
      "Roses are a type of rope used to hold a rope. They are used to hold a rope in place, or to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of wood.\n",
      "\n",
      "Roses are used to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of wood.\n",
      "\n",
      "Roses are used to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of wood.\n",
      "\n",
      "Roses are used to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of wood.\n",
      "\n",
      "Roses are used to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of wood.\n",
      "\n",
      "Roses are used to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of wood.\n",
      "\n",
      "Roses are used to hold a rope in place on a piece of wood. They are also used to hold a rope in place on a piece of\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input text: {input_text}\\n\")\n",
    "print(f\"Output text:\\n{outputs_decoded.replace(prompt, '').replace('<bos>', '').replace('<eos>', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nutrition-style questions generated with GPT4\n",
    "gpt4_questions = [\n",
    "    \"WWhat are the main differences between ROS 1 and ROS 2?\",\n",
    "    \"Explain the concept of topics, services, and actions in ROS.\",\n",
    "    \"What is the purpose of the catkin_make command in ROS 1?\",\n",
    "    \"What is the function of rviz in ROS?\",\n",
    "    \"What is the purpose of rqt_graph, and how can it help in debugging a ROS system?\"\n",
    "] \n",
    "\n",
    "# Manually created question list\n",
    "manual_questions = [\n",
    "    \"What is ros?\",\n",
    "]\n",
    "\n",
    "query_list = gpt4_questions + manual_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: WWhat are the main differences between ROS 1 and ROS 2?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "query = random.choice(query_list)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = qdrant.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=model.encode(query),\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=21, version=0, score=0.5012298822402954, payload={'text': \"and great libraries that's not all. ros is said to be language agnostic. it means that you can program some parts. of your application. in a programming language and another. part\"}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=24, version=0, score=0.4134202003479004, payload={'text': \"powered by ros. using python and c plus plus. ros is also open source with an. active and growing community so. you can directly see what's going on you. can get help\"}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=7, version=0, score=0.4084433913230896, payload={'text': \"so this is the why behind ross. now when to use ros maybe. you've already started to program robots. with. an arduino board with a custom code. on a computer and what you will quickly\"}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=1, version=0, score=0.2859797477722168, payload={'text': \"and a framework built especially for. robotics applications rao's goal. is to provide a standard for robotic. software. that developers can use and reuse in. any robot once you know how to use ros\"}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=16, version=0, score=0.2675519585609436, payload={'text': 'joystick and so on. and each of those independent blocks. will communicate. between each other in a way that. is powerful and scalable. the second main point is that ross'}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Similarity Search and LLM output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
